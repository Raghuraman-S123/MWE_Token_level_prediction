{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-TXGBemGgH"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WsITUAnzvFl"
      },
      "source": [
        "Download the Task data and evaluation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq3qhQdpl-1-",
        "outputId": "11b63aca-e967-4da3-e1de-99c54181d4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SemEval_2022_Task2-idiomaticity' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-0POB9tzfNx"
      },
      "source": [
        "Download the “AStitchInLanguageModels” code which we make use of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affNQCRktdx4",
        "outputId": "68da036d-3654-4932-9431-382c7612ea1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AStitchInLanguageModels' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60w-An2vzikk"
      },
      "source": [
        "Download and install an editable version of huggingfaces transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8BhcLYcmVvd",
        "outputId": "700d8594-68de-4cb3-d743-f637a12c5f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "/content/transformers\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (3.10.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-0.editable-py3-none-any.whl size=35088 sha256=e71be3776f4dff23d06564a95c1352c5b8d9487d2a5e70694c8c9573401af18e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-081aqwtm/wheels/1c/6e/db/b90d9f8554f165a9beb90b593fde94e9e60919270aed78efa0\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.0.dev0\n",
            "    Uninstalling transformers-4.28.0.dev0:\n",
            "      Successfully uninstalled transformers-4.28.0.dev0\n",
            "Successfully installed transformers-4.28.0.dev0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!pip install --editable .\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVMnwTSzmjJ"
      },
      "source": [
        "Required for run_glue ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-GICLy1V-fc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tsWits5tw1t",
        "outputId": "64ffd89d-e182-43f0-83f0-5edce7d8e932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.10.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "## run_glue needs this.\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-igYdTTgzp9e"
      },
      "source": [
        "Editable install requires runtime restart unless we do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOuKplBmmbeB"
      },
      "outputs": [],
      "source": [
        "import site\n",
        "site.main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c4XuSXjSSz2",
        "outputId": "2400784d-073f-4a2d-f481-3f83ca14efec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.28.0.dev0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvC8kAGNnKk_"
      },
      "source": [
        "# Imports and Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOw3MaG7nN77"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import imblearn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzDtW9eXnOhG"
      },
      "outputs": [],
      "source": [
        "def load_csv( path, delimiter=',' ) :\n",
        "  header = None\n",
        "  data   = list()\n",
        "  with open( path, encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader( csvfile, delimiter=delimiter )\n",
        "    for row in reader :\n",
        "      if header is None :\n",
        "        header = row\n",
        "        continue\n",
        "      data.append( row )\n",
        "  return header, data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwtDsdtAnSZu"
      },
      "outputs": [],
      "source": [
        "def write_csv( data, location ) :\n",
        "  with open( location, 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer( csvfile )\n",
        "    writer.writerows( data )\n",
        "  print( \"Wrote {}\".format( location ) )\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Io3D3_z4wt"
      },
      "source": [
        "The following function creates a submission file from the predictions output by run_glue (the text classification script from huggingface transformers - see below).\n",
        "\n",
        "Note that we set it up so we can load up results for only one setting.\n",
        "\n",
        "It requires as input the submission format file, which is available with the data. You can call this after completing each setting to load up results for both settings (see below).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re31vnLoQWww"
      },
      "outputs": [],
      "source": [
        "def insert_to_submission_file( submission_format_file, input_file, prediction_format_file, setting ) :\n",
        "    submission_header, submission_content = load_csv( submission_format_file )\n",
        "    input_header     , input_data         = load_csv( input_file             )\n",
        "    prediction_header, prediction_data    = load_csv( prediction_format_file, '\\t' )\n",
        "\n",
        "    assert len( input_data ) == len( prediction_data )\n",
        "\n",
        "    ## submission_header ['ID', 'Language', 'Setting', 'Label']\n",
        "    ## input_header      ['label', 'sentence1' ]\n",
        "    ## prediction_header ['index', 'prediction']\n",
        "\n",
        "    prediction_data = list( reversed( prediction_data ) )\n",
        "\n",
        "    started_insert  = False\n",
        "    for elem in submission_content :\n",
        "        if elem[ submission_header.index( 'Setting' ) ] != setting :\n",
        "            if started_insert :\n",
        "                if len( prediction_data ) == 0 :\n",
        "                    break\n",
        "                else :\n",
        "                    raise Exception( \"Update should to contiguous ... something wrong.\" )\n",
        "            continue\n",
        "        started_insert = True\n",
        "        elem[ submission_header.index( 'Label' ) ] = prediction_data.pop()[ prediction_header.index( 'prediction' ) ]\n",
        "\n",
        "    return [ submission_header ] + submission_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44LyZ-OXmgQW"
      },
      "source": [
        "# Pre-process: Create train and dev and evaluation data in required format\n",
        "\n",
        "In the zero-shot setting, we choose to include the context (the sentences preceding and succeeding the one containing the idioms). We do not add the idiom as an additional feature (in the “second input sentence”).\n",
        "\n",
        "In the one shot setting, we train the model on both the zero-shot and one-shot data. In this setting, we exclude the context (the sentences preceding and succeeding the one containing the idioms) and also add the idiom as an additional feature in the “second sentence”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-3ymBcEmxaV"
      },
      "source": [
        "## Functions for pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MthVK7EQm6m_"
      },
      "source": [
        "### _get_train_data\n",
        "\n",
        "This function generates training data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPGq-Y1Jmvv5"
      },
      "outputs": [],
      "source": [
        "def _get_train_data( data_location, file_name, include_context, include_idiom,language ) :\n",
        "\n",
        "    file_name = os.path.join( data_location, file_name )\n",
        "\n",
        "    header, data = load_csv( file_name )\n",
        "\n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "\n",
        "    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n",
        "    out_data = list()\n",
        "    for elem in data :\n",
        "        label     = elem[ header.index( 'Label'  ) ]\n",
        "        sentence1 = elem[ header.index( 'Target' ) ]\n",
        "        if language==\"EN\":\n",
        "          if elem[header.index('Language')] != language:\n",
        "            continue\n",
        "        if language==\"PT\":\n",
        "          if elem[header.index('Language')] != language:\n",
        "            continue\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ header.index( 'Previous' ) ], elem[ header.index( 'Target' ) ], elem[ header.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ]\n",
        "        else :\n",
        "            sentence2 = elem[ header.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        out_data.append( this_row )\n",
        "        assert len( out_header ) == len( this_row )\n",
        "    fin=[out_header] + out_data\n",
        "    return fin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cytociCB3WZM"
      },
      "source": [
        "### _get_dev_eval_data\n",
        "\n",
        "This function generates training dev and eval data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters.\n",
        "\n",
        "Additionally, if there is no gold label provides (as in the case of eval) it will generate a file that can be used to generate predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe4YQJ9Sm-B2"
      },
      "outputs": [],
      "source": [
        "def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n",
        "\n",
        "    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n",
        "    gold_header  = gold_data = None\n",
        "    if not gold_file_name is None :\n",
        "        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n",
        "        assert len( input_data ) == len( gold_data )\n",
        "\n",
        "    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
        "    # ['ID', 'DataID', 'Language', 'Label']\n",
        "\n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "\n",
        "    out_data = list()\n",
        "    for index in range( len( input_data ) ) :\n",
        "        label = 1\n",
        "        if not gold_file_name is None :\n",
        "            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n",
        "            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n",
        "            assert this_input_id == this_gold_id\n",
        "\n",
        "            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n",
        "\n",
        "        elem      = input_data[ index ]\n",
        "        sentence1 = elem[ input_headers.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ]\n",
        "        else :\n",
        "            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        assert len( out_header ) == len( this_row )\n",
        "        out_data.append( this_row )\n",
        "\n",
        "\n",
        "    return [ out_header ] + out_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjIbyTnn3fHP"
      },
      "source": [
        "### create_data\n",
        "\n",
        "This function generates the training, development and evaluation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1tr-zNvnBCV"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Based on the results presented in `AStitchInLanguageModels' we work with not including the idiom for the zero shot setting and including it in the one shot setting.\n",
        "\"\"\"\n",
        "def create_data( input_location, output_location ) :\n",
        "\n",
        "\n",
        "    ## Zero shot data\n",
        "    train_data_multi = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'Multi'\n",
        "    )\n",
        "    write_csv( train_data_multi, os.path.join( output_location, 'ZeroShot', 'train_multi.csv' ) )\n",
        "\n",
        "    train_data_en = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'EN'\n",
        "    )\n",
        "    write_csv( train_data_en, os.path.join( output_location, 'ZeroShot', 'train_en.csv' ) )\n",
        "\n",
        "    train_data_PT = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'PT'\n",
        "    )\n",
        "    write_csv( train_data_PT, os.path.join( output_location, 'ZeroShot', 'train_pt.csv' ) )\n",
        "\n",
        "    dev_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv',\n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )\n",
        "    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n",
        "\n",
        "    eval_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )\n",
        "    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n",
        "\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmQfvym8ndKH"
      },
      "source": [
        "## Setup and Create data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxCgaHlKnpMR",
        "outputId": "a61c1c5f-d4f3-469c-86e0-0b5ad56a6b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AStitchInLanguageModels  models       SemEval_2022_Task2-idiomaticity\n",
            "Data\t\t\t sample_data  transformers\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkeKLg-Hngs4",
        "outputId": "879e5d0b-82a5-41b4-ab32-783236bcd162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train_multi.csv\n",
            "Wrote Data/ZeroShot/train_en.csv\n",
            "Wrote Data/ZeroShot/train_pt.csv\n",
            "Wrote Data/ZeroShot/dev.csv\n",
            "Wrote Data/ZeroShot/eval.csv\n"
          ]
        }
      ],
      "source": [
        "outpath = 'Data'\n",
        "\n",
        "Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBQsejtmBf4o",
        "outputId": "c4e3a664-9e59-49f2-e1d7-b2e2834f0b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         DataID Language           MWE    Setting  \\\n",
            "0      train_zero_shot.EN.168.1       EN  double dutch  zero_shot   \n",
            "1      train_zero_shot.EN.168.2       EN  double dutch  zero_shot   \n",
            "2      train_zero_shot.EN.168.3       EN  double dutch  zero_shot   \n",
            "3      train_zero_shot.EN.168.4       EN  double dutch  zero_shot   \n",
            "4      train_zero_shot.EN.168.5       EN  double dutch  zero_shot   \n",
            "...                         ...      ...           ...        ...   \n",
            "4486   train_zero_shot.PT.351.8       PT  gato-pingado  zero_shot   \n",
            "4487   train_zero_shot.PT.351.9       PT  gato-pingado  zero_shot   \n",
            "4488  train_zero_shot.PT.351.10       PT  gato-pingado  zero_shot   \n",
            "4489  train_zero_shot.PT.351.11       PT  gato-pingado  zero_shot   \n",
            "4490  train_zero_shot.PT.351.12       PT  gato-pingado  zero_shot   \n",
            "\n",
            "                                               Previous  \\\n",
            "0     This inspired others to jump ropes as a leisur...   \n",
            "1     In the age of chivalry a man paid for the woma...   \n",
            "2     To her eternal credit, she kept both India and...   \n",
            "3     While pharmaceutical companies were researchin...   \n",
            "4     Coronavirus in Europe   * Brexit   * Brussels ...   \n",
            "...                                                 ...   \n",
            "4486                                 Era o ano de 1968.   \n",
            "4487  De acordo com informações vazadas de dentro da...   \n",
            "4488  O radialista Roberto Toledo apresentou o show ...   \n",
            "4489  O carnaval em Goiânia também tem espaço para o...   \n",
            "4490  A concentração aconteceu na Avenida Circular, ...   \n",
            "\n",
            "                                                 Target  \\\n",
            "0     There are several theories behind the origin o...   \n",
            "1     Double Dutch also derives from the same era, D...   \n",
            "2     Since 1977 we have had a plethora of Foreign M...   \n",
            "3     Turns out that these people were speaking doub...   \n",
            "4              Is Flemish premier talking double Dutch?   \n",
            "...                                                 ...   \n",
            "4486   A estação de passageiros tranquila, com um ou...   \n",
            "4487  Segundo a fonte, o programa vai seguir um form...   \n",
            "4488  \"Eu fiquei sentado no chão e realmente só tinh...   \n",
            "4489  É o caso do bloco “Gato Pingado”, que reuniu c...   \n",
            "4490  De acordo com presidente do bloco, Paulo de Tá...   \n",
            "\n",
            "                                                   Next  Label  \n",
            "0     The most popular theory states that “Double Du...      0  \n",
            "1     There are many phrases that include the word: ...      0  \n",
            "2     We need to exclude from that list the late Mr ...      0  \n",
            "3     So why aren’t Big Macs sold all over the world...      0  \n",
            "4     Three months before the Belgians take over the...      0  \n",
            "...                                                 ...    ...  \n",
            "4486  Com os primeiros raios solares, o potente DC 8...      0  \n",
            "4487  Leonardo fica inchado, perde a voz e vício mor...      0  \n",
            "4488  Entre os poucos espectadores estava o advogado...      0  \n",
            "4489  Segundo os organizadores, quando criaram o blo...      1  \n",
            "4490   “A diferença do bloco é que realmente é um ca...      1  \n",
            "\n",
            "[4491 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "train_multi=pd.read_csv(\"/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/train_zero_shot.csv\")\n",
        "print(train_multi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXJ9sqEHpgMK",
        "outputId": "4f44a22c-3396-437d-ee78-fa18689d72d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train_undersampled_final.csv\n"
          ]
        }
      ],
      "source": [
        "train_multi=pd.read_csv(\"/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/train_zero_shot.csv\")\n",
        "#train_multi_df=pd.DataFrame(train_multi)\n",
        "X=train_multi.drop('Language',axis=1)\n",
        "y=train_multi['Language']\n",
        "under=RandomUnderSampler(sampling_strategy='majority')\n",
        "X_over, y_over = under.fit_resample(X, y)\n",
        "train_multi_undersampled = pd.concat([X_over, y_over], axis=1, join='inner')\n",
        "train_en_undersampled=train_multi_undersampled[train_multi_undersampled['Language']=='EN']\n",
        "filepath=''\n",
        "train_en_undersampled.to_csv('Data/ZeroShot/train_en_undersampled.csv')\n",
        "train_data_multi = _get_train_data(\n",
        "        data_location   = 'Data/ZeroShot/',\n",
        "        file_name       = 'train_en_undersampled.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'Multi'\n",
        "    )\n",
        "write_csv( train_data_multi, os.path.join( 'Data', 'ZeroShot', 'train_undersampled_final.csv' ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq33gURvTIFY",
        "outputId": "00bd4c22-e8ea-4687-a64d-1068e15fcbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train_undersampled_multi_final.csv\n"
          ]
        }
      ],
      "source": [
        "train_multi=pd.read_csv(\"/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/train_zero_shot.csv\")\n",
        "#train_multi_df=pd.DataFrame(train_multi)\n",
        "X=train_multi.drop('Language',axis=1)\n",
        "y=train_multi['Language']\n",
        "under=RandomUnderSampler(sampling_strategy='majority')\n",
        "X_over, y_over = under.fit_resample(X, y)\n",
        "train_multi_undersampled = pd.concat([X_over, y_over], axis=1, join='inner')\n",
        "filepath=''\n",
        "train_en_undersampled.to_csv('Data/ZeroShot/train_en_undersampled.csv')\n",
        "train_data_multi = _get_train_data(\n",
        "        data_location   = 'Data/ZeroShot/',\n",
        "        file_name       = 'train_en_undersampled.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'Multi'\n",
        "    )\n",
        "write_csv( train_data_multi, os.path.join( 'Data', 'ZeroShot', 'train_undersampled_multi_final.csv' ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xo2_HSYud0V"
      },
      "source": [
        "# *MFC class*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bpiJiP-udYo",
        "outputId": "f2ba7421-85d3-4440-df8e-9f1d36dd00f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the MFC for the trained on multilingual data and tested on multilingual data\n",
            "0.4546684709066306\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_multi.csv\"\n",
        "path_test_multi= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test_multi)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the trained on multilingual data and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh6IWq4Y_5l0",
        "outputId": "897bc5e4-1810-4f35-cc9c-070bb6e09537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "3322      0  He has recorded 95 tackles and just 6 sacks si...\n",
            "3323      0  But when the regulars started to return, Ighal...\n",
            "3324      0  My job as a head coach is to make the team as ...\n",
            "3325      0  Golden paper wasps have demanding social lives...\n",
            "3326      0  If only one is selected, mock drafters seem to...\n",
            "\n",
            "[3327 rows x 2 columns]\n",
            "This is the MFC for the trained on multilingual data and multilingual data\n",
            "0.4546684709066306\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_en.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the trained on multilingual data and multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77M-4LDn__6g",
        "outputId": "cc841499-71f9-4ca8-a569-84ab47cd1939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "1         1  Explosões deixam 15 mortos e 500 feridos na Gu...\n",
            "2         1  O protagonista Alexander Pechersky vai liderar...\n",
            "3         1  Às vesperas das eleiçoes, milhares de mulheres...\n",
            "4         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "...     ...                                                ...\n",
            "1159      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "1160      0  De acordo com informações vazadas de dentro da...\n",
            "1161      0  O radialista Roberto Toledo apresentou o show ...\n",
            "1162      1  O carnaval em Goiânia também tem espaço para o...\n",
            "1163      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[1164 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on multilingual data\n",
            "0.4546684709066306\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_pt.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EhjK7hLPugQ",
        "outputId": "565c3482-a851-49bd-fa94-21fdcd01ac59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "4486      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "4487      0  De acordo com informações vazadas de dentro da...\n",
            "4488      0  O radialista Roberto Toledo apresentou o show ...\n",
            "4489      1  O carnaval em Goiânia também tem espaço para o...\n",
            "4490      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[4491 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on multilingual data\n",
            "0.3905579399141631\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_multi.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='EN']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRhhCR-1PunJ",
        "outputId": "ad52e918-4c9b-4c5e-fd54-b276ff542d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "3322      0  He has recorded 95 tackles and just 6 sacks si...\n",
            "3323      0  But when the regulars started to return, Ighal...\n",
            "3324      0  My job as a head coach is to make the team as ...\n",
            "3325      0  Golden paper wasps have demanding social lives...\n",
            "3326      0  If only one is selected, mock drafters seem to...\n",
            "\n",
            "[3327 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on multilingual data\n",
            "0.3905579399141631\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_en.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='EN']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZUv2udfPutu",
        "outputId": "bab8b12c-c09b-4d43-e104-1e3acf44558e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "1         1  Explosões deixam 15 mortos e 500 feridos na Gu...\n",
            "2         1  O protagonista Alexander Pechersky vai liderar...\n",
            "3         1  Às vesperas das eleiçoes, milhares de mulheres...\n",
            "4         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "...     ...                                                ...\n",
            "1159      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "1160      0  De acordo com informações vazadas de dentro da...\n",
            "1161      0  O radialista Roberto Toledo apresentou o show ...\n",
            "1162      1  O carnaval em Goiânia também tem espaço para o...\n",
            "1163      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[1164 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on english data\n",
            "0.3905579399141631\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_pt.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='EN']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on english data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-XOYHDNQawo",
        "outputId": "12d8c197-8159-4730-c7c0-754ef0b76ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "4486      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "4487      0  De acordo com informações vazadas de dentro da...\n",
            "4488      0  O radialista Roberto Toledo apresentou o show ...\n",
            "4489      1  O carnaval em Goiânia também tem espaço para o...\n",
            "4490      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[4491 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on portuguese data\n",
            "0.5641025641025641\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_multi.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='PT']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on portuguese data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN98bxxiQg-J",
        "outputId": "46834711-aaee-4fc4-a302-f330332845d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "3322      0  He has recorded 95 tackles and just 6 sacks si...\n",
            "3323      0  But when the regulars started to return, Ighal...\n",
            "3324      0  My job as a head coach is to make the team as ...\n",
            "3325      0  Golden paper wasps have demanding social lives...\n",
            "3326      0  If only one is selected, mock drafters seem to...\n",
            "\n",
            "[3327 rows x 2 columns]\n",
            "This is the MFC for the english setup and tested on portuguese data\n",
            "0.5641025641025641\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_en.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='PT']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the english setup and tested on portuguese data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP-Ol7hfoC8a"
      },
      "source": [
        "# Zero Shot Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-GiQvnkoL67"
      },
      "source": [
        "## Train Zero shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k0BwA0uoKAu",
        "outputId": "4bc29976-78f1-407b-ef48-753f916c8ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-24 19:00:07.015640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-24 19:00:07.015807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-24 19:00:07.015835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "03/24/2023 19:00:09 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "03/24/2023 19:00:09 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/0/runs/Mar24_19-00-09_fbac96a2f473,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=accuracy,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=models/ZeroShot/0/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/0/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "03/24/2023 19:00:09 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_undersampled_multi_final.csv\n",
            "03/24/2023 19:00:09 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-ad89a5ffefcf1ebc/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 10394.81it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 1784.81it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-ad89a5ffefcf1ebc/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 1031.68it/s]\n",
            "[INFO|configuration_utils.py:668] 2023-03-24 19:00:11,468 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-03-24 19:00:11,471 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:482] 2023-03-24 19:00:12,383 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-03-24 19:00:13,315 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-03-24 19:00:13,316 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 19:00:15,133 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/sentencepiece.bpe.model\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 19:00:15,133 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 19:00:15,133 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 19:00:15,133 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 19:00:15,133 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-03-24 19:00:15,134 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-03-24 19:00:15,134 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2398] 2023-03-24 19:00:15,804 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:3019] 2023-03-24 19:00:18,824 >> Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:3031] 2023-03-24 19:00:18,824 >> Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "03/24/2023 19:00:19 - INFO - __main__ -   Sample 788 of the training set: {'label': 0, 'sentence1': \"And to any of the other warriors out there struggling, please reach out for help; the life you save may be your own, and you are worth saving. To those in the public with a shocked look on their faces, unable to understand what went wrong here in Minneapolis and in Washington, D.C., it's not rocket science. We learn from the past.\", 'input_ids': [0, 3493, 47, 2499, 111, 70, 3789, 1631, 416, 25251, 1810, 2685, 237875, 4, 22936, 58359, 1810, 100, 4358, 74, 70, 6897, 398, 30098, 1543, 186, 935, 10002, 4, 136, 398, 621, 41965, 57, 6496, 5, 717, 8382, 23, 70, 3835, 678, 10, 129517, 297, 6713, 98, 2363, 2577, 7, 4, 51, 2886, 47, 28219, 2367, 23409, 44691, 3688, 23, 4211, 86, 11, 34740, 136, 23, 17955, 4, 391, 5, 441, 5, 4, 442, 25, 7, 959, 13950, 126, 41664, 5, 1401, 30698, 1295, 70, 11015, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "03/24/2023 19:00:19 - INFO - __main__ -   Sample 861 of the training set: {'label': 0, 'sentence1': \"A cheat sheet (also cheatsheet) or crib sheet is a concise set of notes used for quick reference Cheat sheets are so named because they may be used by students without the instructor's knowledge to cheat on a test. However, at higher levels of education where rote memorization is not as important as in basic education, students may be permitted to consult their own notes (crib notes, or crib sheet) during the exam (which is not considered cheating).\", 'input_ids': [0, 62, 290, 257, 155434, 15, 289, 991, 290, 257, 7816, 126, 16, 707, 13625, 275, 155434, 83, 10, 158, 318, 184, 5423, 111, 73048, 11814, 100, 63773, 91067, 5024, 257, 155434, 7, 621, 221, 24, 4806, 6637, 1836, 1543, 186, 11814, 390, 25921, 15490, 70, 196592, 25, 7, 51359, 47, 290, 257, 98, 10, 3034, 5, 33306, 4, 99, 77546, 90926, 111, 53019, 7440, 2062, 67, 40765, 47691, 83, 959, 237, 5526, 237, 23, 62822, 53019, 4, 25921, 1543, 186, 28897, 3674, 47, 75463, 2363, 10002, 73048, 15, 238, 11049, 73048, 4, 707, 13625, 275, 155434, 16, 20271, 70, 42276, 15, 143321, 83, 959, 90698, 290, 26518, 194, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "03/24/2023 19:00:19 - INFO - __main__ -   Sample 82 of the training set: {'label': 1, 'sentence1': \"Senior Trump administration officials have raised the possibility of declaring Trump unable to perform the duties of his office. Crowell & Moring Chairman Philip Inglima said in an interview that the firm has received a “nice number” of responses from law firms, but wouldn't give a number. Many applauded the firm's stance but said they would have to confer with management committees before joining, Inglima said.\", 'input_ids': [0, 49952, 5879, 86052, 51521, 7, 765, 165249, 70, 207116, 111, 8, 18347, 2852, 5879, 51, 2886, 47, 51339, 70, 115, 2449, 111, 1919, 23179, 5, 24727, 19256, 619, 5919, 214, 4841, 481, 669, 90452, 11614, 21045, 2804, 23, 142, 33683, 450, 70, 11037, 1556, 75204, 10, 52, 3466, 14012, 63, 111, 57553, 7, 1295, 27165, 11037, 7, 4, 1284, 68746, 25, 18, 8337, 10, 14012, 5, 52455, 4027, 107948, 297, 70, 11037, 25, 7, 6, 116071, 1284, 2804, 1836, 2806, 765, 47, 158, 2875, 678, 24365, 175352, 7, 8108, 33284, 214, 4, 11614, 21045, 2804, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "[INFO|trainer.py:2091] 2023-03-24 19:00:21,863 >> Loading model from models/ZeroShot/0/checkpoint-282.\n",
            "[INFO|trainer.py:747] 2023-03-24 19:00:27,601 >> The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/content/transformers/src/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1751] 2023-03-24 19:00:39,737 >> ***** Running training *****\n",
            "[INFO|trainer.py:1752] 2023-03-24 19:00:39,738 >>   Num examples = 1164\n",
            "[INFO|trainer.py:1753] 2023-03-24 19:00:39,738 >>   Num Epochs = 9\n",
            "[INFO|trainer.py:1754] 2023-03-24 19:00:39,738 >>   Instantaneous batch size per device = 32\n",
            "[INFO|trainer.py:1755] 2023-03-24 19:00:39,738 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1756] 2023-03-24 19:00:39,738 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1757] 2023-03-24 19:00:39,738 >>   Total optimization steps = 333\n",
            "[INFO|trainer.py:1758] 2023-03-24 19:00:39,739 >>   Number of trainable parameters = 278045186\n",
            "[INFO|trainer.py:1778] 2023-03-24 19:00:39,743 >>   Continuing training from checkpoint, will skip to saved global_step\n",
            "[INFO|trainer.py:1779] 2023-03-24 19:00:39,743 >>   Continuing training from epoch 7\n",
            "[INFO|trainer.py:1780] 2023-03-24 19:00:39,743 >>   Continuing training from global step 282\n",
            "[INFO|trainer.py:1783] 2023-03-24 19:00:39,743 >>   Will skip the first 7 epochs then the first 23 batches in the first epoch. If this takes a lot of time, you can install the latest version of Accelerate with `pip install -U accelerate`.You can also add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n",
            "Skipping the first batches:   0% 0/23 [00:00<?, ?it/s]\n",
            "Skipping the first batches: 100% 23/23 [00:00<00:00, 98.88it/s] \n",
            "\n",
            " 85% 283/333 [00:03<00:00, 73.85it/s]\u001b[A\n",
            " 87% 291/333 [00:09<00:01, 26.16it/s]\u001b[A\n",
            " 89% 295/333 [00:11<00:02, 18.31it/s]\u001b[A[INFO|trainer.py:747] 2023-03-24 19:00:51,712 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:3080] 2023-03-24 19:00:51,714 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3082] 2023-03-24 19:00:51,714 >>   Num examples = 739\n",
            "[INFO|trainer.py:3085] 2023-03-24 19:00:51,714 >>   Batch size = 8\n",
            " 99% 92/93 [00:04<00:00, 19.75it/s]\n",
            "{'eval_loss': 0.7498313188552856, 'eval_accuracy': 0.6833558678627014, 'eval_f1': 0.6820698936592684, 'eval_runtime': 4.6828, 'eval_samples_per_second': 157.811, 'eval_steps_per_second': 19.86, 'epoch': 8.0}\n",
            "\n",
            "[INFO|trainer.py:2826] 2023-03-24 19:00:56,398 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-296\n",
            "[INFO|configuration_utils.py:457] 2023-03-24 19:00:56,400 >> Configuration saved in models/ZeroShot/0/checkpoint-296/config.json\n",
            "[INFO|modeling_utils.py:1759] 2023-03-24 19:01:01,220 >> Model weights saved in models/ZeroShot/0/checkpoint-296/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2164] 2023-03-24 19:01:01,221 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-296/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-03-24 19:01:01,221 >> Special tokens file saved in models/ZeroShot/0/checkpoint-296/special_tokens_map.json\n",
            "\n",
            " 89% 296/333 [00:30<00:02, 18.31it/s]\u001b[A[INFO|trainer.py:2904] 2023-03-24 19:01:11,502 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-282] due to args.save_total_limit\n",
            "\n",
            " 89% 297/333 [00:32<00:09,  3.98it/s]\u001b[A\n",
            " 89% 298/333 [00:33<00:08,  3.89it/s]\u001b[A\n",
            " 90% 300/333 [00:34<00:08,  3.68it/s]\u001b[A\n",
            " 90% 301/333 [00:35<00:09,  3.55it/s]\u001b[A\n",
            " 91% 302/333 [00:35<00:09,  3.39it/s]\u001b[A\n",
            " 91% 303/333 [00:36<00:09,  3.21it/s]\u001b[A\n",
            " 91% 304/333 [00:37<00:09,  2.99it/s]\u001b[A\n",
            " 92% 305/333 [00:37<00:10,  2.77it/s]\u001b[A\n",
            " 92% 306/333 [00:38<00:10,  2.54it/s]\u001b[A\n",
            " 92% 307/333 [00:39<00:11,  2.34it/s]\u001b[A\n",
            " 92% 308/333 [00:39<00:11,  2.15it/s]\u001b[A\n",
            " 93% 309/333 [00:40<00:11,  2.00it/s]\u001b[A\n",
            " 93% 310/333 [00:41<00:12,  1.88it/s]\u001b[A\n",
            " 93% 311/333 [00:41<00:12,  1.78it/s]\u001b[A\n",
            " 94% 312/333 [00:42<00:12,  1.71it/s]\u001b[A\n",
            " 94% 313/333 [00:43<00:12,  1.65it/s]\u001b[A\n",
            " 94% 314/333 [00:43<00:11,  1.61it/s]\u001b[A\n",
            " 95% 315/333 [00:44<00:11,  1.58it/s]\u001b[A\n",
            " 95% 316/333 [00:45<00:10,  1.56it/s]\u001b[A\n",
            " 95% 317/333 [00:45<00:10,  1.54it/s]\u001b[A\n",
            " 95% 318/333 [00:46<00:09,  1.53it/s]\u001b[A\n",
            " 96% 319/333 [00:47<00:09,  1.52it/s]\u001b[A\n",
            " 96% 320/333 [00:47<00:08,  1.51it/s]\u001b[A\n",
            " 96% 321/333 [00:48<00:07,  1.51it/s]\u001b[A\n",
            " 97% 322/333 [00:49<00:07,  1.51it/s]\u001b[A\n",
            " 97% 323/333 [00:49<00:06,  1.51it/s]\u001b[A\n",
            " 97% 324/333 [00:50<00:05,  1.50it/s]\u001b[A\n",
            " 98% 325/333 [00:51<00:05,  1.50it/s]\u001b[A\n",
            " 98% 326/333 [00:51<00:04,  1.50it/s]\u001b[A\n",
            " 98% 327/333 [00:52<00:03,  1.50it/s]\u001b[A\n",
            " 98% 328/333 [00:53<00:03,  1.51it/s]\u001b[A\n",
            " 99% 329/333 [00:53<00:02,  1.50it/s]\u001b[A\n",
            " 99% 330/333 [00:54<00:01,  1.50it/s]\u001b[A\n",
            " 99% 331/333 [00:55<00:01,  1.50it/s]\u001b[A\n",
            "100% 332/333 [00:55<00:00,  1.50it/s]\u001b[A\n",
            "100% 333/333 [00:56<00:00,  1.76it/s]\u001b[A[INFO|trainer.py:747] 2023-03-24 19:01:35,839 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:3080] 2023-03-24 19:01:35,841 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3082] 2023-03-24 19:01:35,841 >>   Num examples = 739\n",
            "[INFO|trainer.py:3085] 2023-03-24 19:01:35,841 >>   Batch size = 8\n",
            " 98% 91/93 [00:04<00:00, 19.16it/s]\n",
            "{'eval_loss': 0.8213624954223633, 'eval_accuracy': 0.6833558678627014, 'eval_f1': 0.6823782234957021, 'eval_runtime': 4.8091, 'eval_samples_per_second': 153.666, 'eval_steps_per_second': 19.338, 'epoch': 9.0}\n",
            "\n",
            "[INFO|trainer.py:2826] 2023-03-24 19:01:40,651 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-333\n",
            "[INFO|configuration_utils.py:457] 2023-03-24 19:01:40,653 >> Configuration saved in models/ZeroShot/0/checkpoint-333/config.json\n",
            "[INFO|modeling_utils.py:1759] 2023-03-24 19:01:45,599 >> Model weights saved in models/ZeroShot/0/checkpoint-333/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2164] 2023-03-24 19:01:45,603 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-333/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-03-24 19:01:45,603 >> Special tokens file saved in models/ZeroShot/0/checkpoint-333/special_tokens_map.json\n",
            "[INFO|trainer.py:2021] 2023-03-24 19:01:55,585 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:2141] 2023-03-24 19:01:55,585 >> Loading best model from models/ZeroShot/0/checkpoint-296 (score: 0.6833558678627014).\n",
            "\n",
            "\u001b[A{'train_runtime': 82.4164, 'train_samples_per_second': 127.111, 'train_steps_per_second': 4.04, 'train_loss': 0.03325661095055016, 'epoch': 9.0}\n",
            "\n",
            "100% 333/333 [01:22<00:00,  1.76it/s]\u001b[A[INFO|trainer.py:2055] 2023-03-24 19:02:02,162 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-333] due to args.save_total_limit\n",
            "100% 333/333 [01:22<00:00,  4.03it/s]\n",
            "[INFO|trainer.py:2826] 2023-03-24 19:02:02,477 >> Saving model checkpoint to models/ZeroShot/0/\n",
            "[INFO|configuration_utils.py:457] 2023-03-24 19:02:02,478 >> Configuration saved in models/ZeroShot/0/config.json\n",
            "[INFO|modeling_utils.py:1759] 2023-03-24 19:02:06,997 >> Model weights saved in models/ZeroShot/0/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2164] 2023-03-24 19:02:06,998 >> tokenizer config file saved in models/ZeroShot/0/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-03-24 19:02:06,998 >> Special tokens file saved in models/ZeroShot/0/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        9.0\n",
            "  train_loss               =     0.0333\n",
            "  train_runtime            = 0:01:22.41\n",
            "  train_samples            =       1164\n",
            "  train_samples_per_second =    127.111\n",
            "  train_steps_per_second   =       4.04\n",
            "03/24/2023 19:02:07 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:747] 2023-03-24 19:02:07,468 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:3080] 2023-03-24 19:02:07,477 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3082] 2023-03-24 19:02:07,477 >>   Num examples = 739\n",
            "[INFO|trainer.py:3085] 2023-03-24 19:02:07,477 >>   Batch size = 8\n",
            "100% 93/93 [00:04<00:00, 19.70it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        9.0\n",
            "  eval_accuracy           =     0.6834\n",
            "  eval_f1                 =     0.6821\n",
            "  eval_loss               =     0.7498\n",
            "  eval_runtime            = 0:00:04.80\n",
            "  eval_samples            =        739\n",
            "  eval_samples_per_second =    153.729\n",
            "  eval_steps_per_second   =     19.346\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path 'xlm-roberta-base' \\\n",
        "    \t--do_train \\\n",
        "    \t--do_eval \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/0/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"accuracy\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsA8WGYBFICe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5460c4-2beb-492a-deb4-1f431dd0c89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-24 18:55:44.348191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-24 18:55:44.348344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-24 18:55:44.348366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "03/24/2023 18:55:47 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "03/24/2023 18:55:47 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/11/runs/Mar24_18-55-47_fbac96a2f473,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=accuracy,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=models/ZeroShot/11/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/11/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "03/24/2023 18:55:47 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_en.csv\n",
            "03/24/2023 18:55:47 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-49e82dea5f169706/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 7469.82it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 1186.34it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-49e82dea5f169706/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 307.83it/s]\n",
            "[INFO|configuration_utils.py:668] 2023-03-24 18:55:49,247 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-03-24 18:55:49,255 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:482] 2023-03-24 18:55:50,221 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-03-24 18:55:51,165 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-03-24 18:55:51,166 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 18:55:53,026 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/sentencepiece.bpe.model\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 18:55:53,026 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 18:55:53,026 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 18:55:53,026 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1803] 2023-03-24 18:55:53,026 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-03-24 18:55:53,026 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-03-24 18:55:53,027 >> Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2398] 2023-03-24 18:55:55,114 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:3019] 2023-03-24 18:56:06,184 >> Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:3031] 2023-03-24 18:56:06,185 >> Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "03/24/2023 18:56:08 - INFO - __main__ -   Sample 1577 of the training set: {'label': 1, 'sentence1': 'Where do I stream Stag Night online? Stag Night is available to watch and stream, download, buy on demand at Amazon Prime, Amazon, Vudu, Google Play, iTunes, YouTube VOD online. Some platforms allow you to rent Stag Night for a limited time or purchase the movie and download it to your device.', 'input_ids': [0, 78662, 54, 87, 75973, 159, 6936, 36151, 1118, 32, 159, 6936, 36151, 83, 19882, 47, 39544, 136, 75973, 4, 7026, 4, 22113, 98, 35968, 99, 15075, 56195, 4, 15075, 4, 310, 13017, 4, 1815, 11356, 4, 72975, 4, 12639, 6, 120272, 1118, 5, 31384, 13651, 7, 63769, 398, 47, 14457, 159, 6936, 36151, 100, 10, 84046, 1733, 707, 59038, 70, 14277, 136, 7026, 442, 47, 935, 75186, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "03/24/2023 18:56:08 - INFO - __main__ -   Sample 3104 of the training set: {'label': 1, 'sentence1': 'Did Biden think for himself before he reversed direction on the Keystone Pipeline or did he do it just because the last Democrat president, under whom he served, was against it? I applaud Biden’s decisions to rejoin the World Health Organization and to call a world conference on climate change because, for whatever reason, the climate is changing. The atmosphere is getting warmer and the storms are getting bigger, as evidenced by the one in California earlier this week.', 'input_ids': [0, 37307, 1843, 555, 5351, 100, 66570, 8108, 764, 39531, 5281, 48225, 98, 70, 26824, 34165, 93128, 59760, 707, 6777, 764, 54, 442, 1660, 6637, 70, 4568, 138235, 13918, 4, 1379, 136565, 764, 149976, 4, 509, 26548, 442, 32, 87, 4027, 107948, 1843, 555, 26, 7, 115299, 47, 456, 513, 73, 70, 6661, 19102, 173101, 136, 47, 11782, 10, 8999, 108870, 98, 153552, 15549, 6637, 4, 100, 89778, 31635, 4, 70, 153552, 83, 151134, 5, 581, 225748, 83, 20949, 24814, 56, 136, 70, 77076, 7, 621, 20949, 167785, 4, 237, 77950, 71, 390, 70, 1632, 23, 39897, 110680, 903, 5895, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "03/24/2023 18:56:08 - INFO - __main__ -   Sample 1722 of the training set: {'label': 1, 'sentence1': 'Mank leads the Critics Choice Awards 2021 nominations Coronavirus latest: Covid national research project will study effects of emerging mutations Jared Kushner and Ivanka Trump made up to $640 million while working in White House, report finds', 'input_ids': [0, 1572, 92, 37105, 7, 70, 180423, 7, 181948, 54530, 64371, 27154, 5256, 196458, 76912, 42850, 12, 1311, 5518, 15889, 25188, 13452, 1221, 35187, 93425, 111, 50419, 9966, 199334, 7, 823, 2822, 77225, 1679, 136, 23698, 161, 5879, 7228, 1257, 47, 3650, 169898, 19879, 12960, 20697, 23, 22392, 13038, 4, 13416, 7413, 7, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "[INFO|trainer.py:747] 2023-03-24 18:56:14,874 >> The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/content/transformers/src/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1751] 2023-03-24 18:56:14,896 >> ***** Running training *****\n",
            "[INFO|trainer.py:1752] 2023-03-24 18:56:14,900 >>   Num examples = 3327\n",
            "[INFO|trainer.py:1753] 2023-03-24 18:56:14,900 >>   Num Epochs = 9\n",
            "[INFO|trainer.py:1754] 2023-03-24 18:56:14,900 >>   Instantaneous batch size per device = 32\n",
            "[INFO|trainer.py:1755] 2023-03-24 18:56:14,900 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1756] 2023-03-24 18:56:14,900 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1757] 2023-03-24 18:56:14,900 >>   Total optimization steps = 936\n",
            "[INFO|trainer.py:1758] 2023-03-24 18:56:14,901 >>   Number of trainable parameters = 278045186\n",
            "  2% 19/936 [00:14<10:48,  1.41it/s]Traceback (most recent call last):\n",
            "  File \"/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py\", line 537, in <module>\n",
            "    main()\n",
            "  File \"/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py\", line 469, in main\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 1644, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 1911, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs)\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 2657, in training_step\n",
            "    loss = self.compute_loss(model, inputs)\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 2689, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 1222, in forward\n",
            "    outputs = self.roberta(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 854, in forward\n",
            "    encoder_outputs = self.encoder(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 528, in forward\n",
            "    layer_outputs = layer_module(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 412, in forward\n",
            "    self_attention_outputs = self.attention(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 348, in forward\n",
            "    attention_output = self.output(self_outputs[0], hidden_states)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 298, in forward\n",
            "    hidden_states = self.dropout(hidden_states)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1189, in _call_impl\n",
            "    forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
            "KeyboardInterrupt\n",
            "  2% 19/936 [00:14<11:51,  1.29it/s]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path 'xlm-roberta-base' \\\n",
        "    \t--do_train \\\n",
        "    \t--do_eval \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/11/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_en.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"accuracy\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54PqcPHuFLgk"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path 'xlm-roberta-base' \\\n",
        "    \t--do_train \\\n",
        "    \t--do_eval \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/2/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_pt.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"accuracy\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFFqAwoaFDWi"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path 'xlm-roberta-base' \\\n",
        "    \t--do_train \\\n",
        "    \t--do_eval \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/6/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"accuracy\" \\\n",
        "\t    --save_total_limit 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGlY2qvVTQ1X"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path 'xlm-roberta-base' \\\n",
        "    \t--do_train \\\n",
        "    \t--do_eval \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/5/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"accuracy\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrfwDiORPDyS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibb2Uo0vPPc3"
      },
      "outputs": [],
      "source": [
        "## Create save path\n",
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/0/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bnemEFMFllZ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/11/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd5n2LxvFlxB"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/2/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/2/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a01lXW3pE86c"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/6/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/6/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/6/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0s4_Y2YTaSs"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/5/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/5/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/5/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_ag-2oV4Egv"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/SemEval_2022_Task2-idiomaticity\n",
        "## Copy saved model.\n",
        "!cp -r SemEval_2022_Task2-idiomaticity/* /content/gdrive/MyDrive/SemEval_2022_Task2-idiomaticity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etL-Ic6bPmtA"
      },
      "outputs": [],
      "source": [
        "## Bring back saved model here.\n",
        "#!mkdir -p /content/models/ZeroShot/0/\n",
        "# !cp -r /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/* /content/models/ZeroShot/0/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bN4iUHWP45b"
      },
      "source": [
        "## Evaluation On Dev Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "houOZpcYO-Pw"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/0/eval-dev/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_multi.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W0KeQZPFADP"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/11/eval-dev/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_en.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDb4e_UyFzaO"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/2/' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/2/eval-dev/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_pt.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhV-IAvwFMo7"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/6/' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/6/eval-dev/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3P5QsGNTf27"
      },
      "outputs": [],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/5/' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/5/eval-dev/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHqPYuTS3muJ"
      },
      "source": [
        "### Use predictions to create the submission file (for dev data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfWUuwg7Qm-t"
      },
      "outputs": [],
      "source": [
        "params_multi = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/0/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_multi[ 'setting' ] = 'zero_shot'\n",
        "params_en = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/11/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_en[ 'setting' ] = 'zero_shot'\n",
        "params_pt = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/2/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_pt[ 'setting' ] = 'zero_shot'\n",
        "params_undersampled = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/6/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_undersampled[ 'setting' ] = 'zero_shot'\n",
        "params_undersampled_multi = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/5/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_undersampled_multi[ 'setting' ] = 'zero_shot'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgFGlGnTROJZ"
      },
      "outputs": [],
      "source": [
        "updated_data_multi = insert_to_submission_file( **params_multi )\n",
        "updated_data_en = insert_to_submission_file( **params_en )\n",
        "updated_data_pt = insert_to_submission_file( **params_pt )\n",
        "updated_data_undersampled = insert_to_submission_file( **params_undersampled )\n",
        "updated_data_undersampled_multi = insert_to_submission_file( **params_undersampled_multi )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8-WO4T8LBgV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXcRbv70RZfR"
      },
      "outputs": [],
      "source": [
        "!mkdir -p outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ezIzyWTRePp"
      },
      "outputs": [],
      "source": [
        "write_csv( updated_data_multi, 'outputs/zero_shot_dev_formated_multi.csv' )\n",
        "write_csv( updated_data_en, 'outputs/zero_shot_dev_formated_en.csv' )\n",
        "write_csv( updated_data_pt, 'outputs/zero_shot_dev_formated_pt.csv' )\n",
        "write_csv( updated_data_undersampled, 'outputs/zero_shot_dev_formated_undersampled.csv' )\n",
        "write_csv( updated_data_undersampled_multi, 'outputs/zero_shot_dev_formated_undersampled_multi.csv' )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}