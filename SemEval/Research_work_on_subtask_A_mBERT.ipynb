{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-TXGBemGgH"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WsITUAnzvFl"
      },
      "source": [
        "Download the Task data and evaluation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq3qhQdpl-1-",
        "outputId": "04f13db6-d452-4e1e-8fc7-2abaff707eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemEval_2022_Task2-idiomaticity'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 123 (delta 48), reused 61 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (123/123), 2.50 MiB | 10.55 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-0POB9tzfNx"
      },
      "source": [
        "Download the “AStitchInLanguageModels” code which we make use of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affNQCRktdx4",
        "outputId": "a1ec0352-ce4a-4510-c324-7a81238d3d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AStitchInLanguageModels'...\n",
            "remote: Enumerating objects: 1030, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 1030 (delta 11), reused 4 (delta 4), pack-reused 1013\u001b[K\n",
            "Receiving objects: 100% (1030/1030), 79.59 MiB | 17.41 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60w-An2vzikk"
      },
      "source": [
        "Download and install an editable version of huggingfaces transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8BhcLYcmVvd",
        "outputId": "7506d07f-5c0e-43ab-b902-3d3f5cea1e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 133802, done.\u001b[K\n",
            "remote: Counting objects: 100% (408/408), done.\u001b[K\n",
            "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
            "remote: Total 133802 (delta 232), reused 308 (delta 176), pack-reused 133394\u001b[K\n",
            "Receiving objects: 100% (133802/133802), 131.31 MiB | 16.54 MiB/s, done.\n",
            "Resolving deltas: 100% (100694/100694), done.\n",
            "/content/transformers\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (3.10.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-0.editable-py3-none-any.whl size=35089 sha256=4c5156e0a780a0c979e857410056f283f043160fe1a51ab1f3b40b2c87f14977\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ovgfdyv1/wheels/1c/6e/db/b90d9f8554f165a9beb90b593fde94e9e60919270aed78efa0\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.28.0.dev0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!pip install --editable .\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVMnwTSzmjJ"
      },
      "source": [
        "Required for run_glue ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-GICLy1V-fc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tsWits5tw1t",
        "outputId": "9d05963c-d4cc-49e7-e7db-1a6ed511944c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "## run_glue needs this.\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-igYdTTgzp9e"
      },
      "source": [
        "Editable install requires runtime restart unless we do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOuKplBmmbeB"
      },
      "outputs": [],
      "source": [
        "import site\n",
        "site.main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c4XuSXjSSz2",
        "outputId": "e2e419c3-e551-4f8f-9dc1-72ac65bd76a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.28.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=0e9bab17e1be8bd0b1017c448857888d8cc12a955c2fed60a1a41884110d4a1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbobd0WhVGXH",
        "outputId": "614d5ace-c5f6-4acb-d667-c30447ac6c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.9/dist-packages (from bertviz) (1.13.1+cu116)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from bertviz) (0.1.97)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.98-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from bertviz) (4.65.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from bertviz) (2022.10.31)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.9/dist-packages (from bertviz) (4.28.0.dev0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from bertviz) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->bertviz) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (3.10.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.0->bertviz) (1.22.4)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.98\n",
            "  Downloading botocore-1.29.98-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->bertviz) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.98->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.98->boto3->bertviz) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, bertviz\n",
            "Successfully installed bertviz-1.4.0 boto3-1.26.98 botocore-1.29.98 jmespath-1.0.1 s3transfer-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install bertviz\n",
        "from bertviz import head_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvC8kAGNnKk_"
      },
      "source": [
        "# Imports and Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOw3MaG7nN77"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import imblearn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzDtW9eXnOhG"
      },
      "outputs": [],
      "source": [
        "def load_csv( path, delimiter=',' ) :\n",
        "  header = None\n",
        "  data   = list()\n",
        "  with open( path, encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader( csvfile, delimiter=delimiter )\n",
        "    for row in reader :\n",
        "      if header is None :\n",
        "        header = row\n",
        "        continue\n",
        "      data.append( row )\n",
        "  return header, data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwtDsdtAnSZu"
      },
      "outputs": [],
      "source": [
        "def write_csv( data, location ) :\n",
        "  with open( location, 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer( csvfile )\n",
        "    writer.writerows( data )\n",
        "  print( \"Wrote {}\".format( location ) )\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Io3D3_z4wt"
      },
      "source": [
        "The following function creates a submission file from the predictions output by run_glue (the text classification script from huggingface transformers - see below).\n",
        "\n",
        "Note that we set it up so we can load up results for only one setting.\n",
        "\n",
        "It requires as input the submission format file, which is available with the data. You can call this after completing each setting to load up results for both settings (see below).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re31vnLoQWww"
      },
      "outputs": [],
      "source": [
        "def insert_to_submission_file( submission_format_file, input_file, prediction_format_file, setting ) :\n",
        "    submission_header, submission_content = load_csv( submission_format_file )\n",
        "    input_header     , input_data         = load_csv( input_file             )\n",
        "    prediction_header, prediction_data    = load_csv( prediction_format_file, '\\t' )\n",
        "\n",
        "    assert len( input_data ) == len( prediction_data )\n",
        "\n",
        "    ## submission_header ['ID', 'Language', 'Setting', 'Label']\n",
        "    ## input_header      ['label', 'sentence1' ]\n",
        "    ## prediction_header ['index', 'prediction']\n",
        "\n",
        "    prediction_data = list( reversed( prediction_data ) )\n",
        "\n",
        "    started_insert  = False\n",
        "    for elem in submission_content :\n",
        "        if elem[ submission_header.index( 'Setting' ) ] != setting :\n",
        "            if started_insert :\n",
        "                if len( prediction_data ) == 0 :\n",
        "                    break\n",
        "                else :\n",
        "                    raise Exception( \"Update should to contiguous ... something wrong.\" )\n",
        "            continue\n",
        "        started_insert = True\n",
        "        elem[ submission_header.index( 'Label' ) ] = prediction_data.pop()[ prediction_header.index( 'prediction' ) ]\n",
        "\n",
        "    return [ submission_header ] + submission_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44LyZ-OXmgQW"
      },
      "source": [
        "# Pre-process: Create train and dev and evaluation data in required format\n",
        "\n",
        "In the zero-shot setting, we choose to include the context (the sentences preceding and succeeding the one containing the idioms). We do not add the idiom as an additional feature (in the “second input sentence”).\n",
        "\n",
        "In the one shot setting, we train the model on both the zero-shot and one-shot data. In this setting, we exclude the context (the sentences preceding and succeeding the one containing the idioms) and also add the idiom as an additional feature in the “second sentence”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-3ymBcEmxaV"
      },
      "source": [
        "## Functions for pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MthVK7EQm6m_"
      },
      "source": [
        "### _get_train_data\n",
        "\n",
        "This function generates training data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPGq-Y1Jmvv5"
      },
      "outputs": [],
      "source": [
        "def _get_train_data( data_location, file_name, include_context, include_idiom,language ) :\n",
        "\n",
        "    file_name = os.path.join( data_location, file_name )\n",
        "\n",
        "    header, data = load_csv( file_name )\n",
        "\n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "\n",
        "    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n",
        "    out_data = list()\n",
        "    for elem in data :\n",
        "        label     = elem[ header.index( 'Label'  ) ]\n",
        "        sentence1 = elem[ header.index( 'Target' ) ]\n",
        "        if language==\"EN\":\n",
        "          if elem[header.index('Language')] != language:\n",
        "            continue\n",
        "        if language==\"PT\":\n",
        "          if elem[header.index('Language')] != language:\n",
        "            continue\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ header.index( 'Previous' ) ], elem[ header.index( 'Target' ) ], elem[ header.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ]\n",
        "        else :\n",
        "            sentence2 = elem[ header.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        out_data.append( this_row )\n",
        "        assert len( out_header ) == len( this_row )\n",
        "    fin=[out_header] + out_data\n",
        "    return fin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cytociCB3WZM"
      },
      "source": [
        "### _get_dev_eval_data\n",
        "\n",
        "This function generates training dev and eval data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters.\n",
        "\n",
        "Additionally, if there is no gold label provides (as in the case of eval) it will generate a file that can be used to generate predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe4YQJ9Sm-B2"
      },
      "outputs": [],
      "source": [
        "def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n",
        "\n",
        "    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n",
        "    gold_header  = gold_data = None\n",
        "    if not gold_file_name is None :\n",
        "        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n",
        "        assert len( input_data ) == len( gold_data )\n",
        "\n",
        "    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
        "    # ['ID', 'DataID', 'Language', 'Label']\n",
        "\n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "\n",
        "    out_data = list()\n",
        "    for index in range( len( input_data ) ) :\n",
        "        label = 1\n",
        "        if not gold_file_name is None :\n",
        "            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n",
        "            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n",
        "            assert this_input_id == this_gold_id\n",
        "\n",
        "            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n",
        "\n",
        "        elem      = input_data[ index ]\n",
        "        sentence1 = elem[ input_headers.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ]\n",
        "        else :\n",
        "            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        assert len( out_header ) == len( this_row )\n",
        "        out_data.append( this_row )\n",
        "\n",
        "\n",
        "    return [ out_header ] + out_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjIbyTnn3fHP"
      },
      "source": [
        "### create_data\n",
        "\n",
        "This function generates the training, development and evaluation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1tr-zNvnBCV"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Based on the results presented in `AStitchInLanguageModels' we work with not including the idiom for the zero shot setting and including it in the one shot setting.\n",
        "\"\"\"\n",
        "def create_data( input_location, output_location ) :\n",
        "\n",
        "\n",
        "    ## Zero shot data\n",
        "    train_data_multi = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'Multi'\n",
        "    )\n",
        "    write_csv( train_data_multi, os.path.join( output_location, 'ZeroShot', 'train_multi.csv' ) )\n",
        "\n",
        "    train_data_en = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'EN'\n",
        "    )\n",
        "    write_csv( train_data_en, os.path.join( output_location, 'ZeroShot', 'train_en.csv' ) )\n",
        "\n",
        "    train_data_PT = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'PT'\n",
        "    )\n",
        "    write_csv( train_data_PT, os.path.join( output_location, 'ZeroShot', 'train_pt.csv' ) )\n",
        "\n",
        "    dev_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv',\n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )\n",
        "    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n",
        "\n",
        "    eval_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )\n",
        "    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n",
        "\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmQfvym8ndKH"
      },
      "source": [
        "## Setup and Create data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxCgaHlKnpMR",
        "outputId": "e12061ce-256c-498c-b106-75c5d02f5fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AStitchInLanguageModels  SemEval_2022_Task2-idiomaticity\n",
            "sample_data\t\t transformers\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkeKLg-Hngs4",
        "outputId": "2eb155cd-8bde-4a50-de00-7d761f028efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train_multi.csv\n",
            "Wrote Data/ZeroShot/train_en.csv\n",
            "Wrote Data/ZeroShot/train_pt.csv\n",
            "Wrote Data/ZeroShot/dev.csv\n",
            "Wrote Data/ZeroShot/eval.csv\n"
          ]
        }
      ],
      "source": [
        "outpath = 'Data'\n",
        "\n",
        "Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBQsejtmBf4o",
        "outputId": "df8675be-bc4b-4a0c-9d40-f072ec41a5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         DataID Language           MWE    Setting  \\\n",
            "0      train_zero_shot.EN.168.1       EN  double dutch  zero_shot   \n",
            "1      train_zero_shot.EN.168.2       EN  double dutch  zero_shot   \n",
            "2      train_zero_shot.EN.168.3       EN  double dutch  zero_shot   \n",
            "3      train_zero_shot.EN.168.4       EN  double dutch  zero_shot   \n",
            "4      train_zero_shot.EN.168.5       EN  double dutch  zero_shot   \n",
            "...                         ...      ...           ...        ...   \n",
            "4486   train_zero_shot.PT.351.8       PT  gato-pingado  zero_shot   \n",
            "4487   train_zero_shot.PT.351.9       PT  gato-pingado  zero_shot   \n",
            "4488  train_zero_shot.PT.351.10       PT  gato-pingado  zero_shot   \n",
            "4489  train_zero_shot.PT.351.11       PT  gato-pingado  zero_shot   \n",
            "4490  train_zero_shot.PT.351.12       PT  gato-pingado  zero_shot   \n",
            "\n",
            "                                               Previous  \\\n",
            "0     This inspired others to jump ropes as a leisur...   \n",
            "1     In the age of chivalry a man paid for the woma...   \n",
            "2     To her eternal credit, she kept both India and...   \n",
            "3     While pharmaceutical companies were researchin...   \n",
            "4     Coronavirus in Europe   * Brexit   * Brussels ...   \n",
            "...                                                 ...   \n",
            "4486                                 Era o ano de 1968.   \n",
            "4487  De acordo com informações vazadas de dentro da...   \n",
            "4488  O radialista Roberto Toledo apresentou o show ...   \n",
            "4489  O carnaval em Goiânia também tem espaço para o...   \n",
            "4490  A concentração aconteceu na Avenida Circular, ...   \n",
            "\n",
            "                                                 Target  \\\n",
            "0     There are several theories behind the origin o...   \n",
            "1     Double Dutch also derives from the same era, D...   \n",
            "2     Since 1977 we have had a plethora of Foreign M...   \n",
            "3     Turns out that these people were speaking doub...   \n",
            "4              Is Flemish premier talking double Dutch?   \n",
            "...                                                 ...   \n",
            "4486   A estação de passageiros tranquila, com um ou...   \n",
            "4487  Segundo a fonte, o programa vai seguir um form...   \n",
            "4488  \"Eu fiquei sentado no chão e realmente só tinh...   \n",
            "4489  É o caso do bloco “Gato Pingado”, que reuniu c...   \n",
            "4490  De acordo com presidente do bloco, Paulo de Tá...   \n",
            "\n",
            "                                                   Next  Label  \n",
            "0     The most popular theory states that “Double Du...      0  \n",
            "1     There are many phrases that include the word: ...      0  \n",
            "2     We need to exclude from that list the late Mr ...      0  \n",
            "3     So why aren’t Big Macs sold all over the world...      0  \n",
            "4     Three months before the Belgians take over the...      0  \n",
            "...                                                 ...    ...  \n",
            "4486  Com os primeiros raios solares, o potente DC 8...      0  \n",
            "4487  Leonardo fica inchado, perde a voz e vício mor...      0  \n",
            "4488  Entre os poucos espectadores estava o advogado...      0  \n",
            "4489  Segundo os organizadores, quando criaram o blo...      1  \n",
            "4490   “A diferença do bloco é que realmente é um ca...      1  \n",
            "\n",
            "[4491 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "train_multi=pd.read_csv(\"/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/train_zero_shot.csv\")\n",
        "print(train_multi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXJ9sqEHpgMK",
        "outputId": "458054c2-d76c-4e11-de78-fadceaadaa07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train_undersampled_final.csv\n"
          ]
        }
      ],
      "source": [
        "train_multi=pd.read_csv(\"/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/train_zero_shot.csv\")\n",
        "#train_multi_df=pd.DataFrame(train_multi)\n",
        "X=train_multi.drop('Language',axis=1)\n",
        "y=train_multi['Language']\n",
        "under=RandomUnderSampler(sampling_strategy='majority')\n",
        "X_over, y_over = under.fit_resample(X, y)\n",
        "train_multi_undersampled = pd.concat([X_over, y_over], axis=1, join='inner')\n",
        "train_en_undersampled=train_multi_undersampled[train_multi_undersampled['Language']=='EN']\n",
        "filepath=''\n",
        "train_en_undersampled.to_csv('Data/ZeroShot/train_en_undersampled.csv')\n",
        "train_data_multi = _get_train_data(\n",
        "        data_location   = 'Data/ZeroShot/',\n",
        "        file_name       = 'train_en_undersampled.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'Multi'\n",
        "    )\n",
        "write_csv( train_data_multi, os.path.join( 'Data', 'ZeroShot', 'train_undersampled_final.csv' ) )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_en_undersampled)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntJKErNXIzvD",
        "outputId": "f83c2f0c-bb99-41fe-c0e2-661a8811ef5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         DataID                MWE    Setting  \\\n",
            "0     train_zero_shot.EN.114.20          fair play  zero_shot   \n",
            "1     train_zero_shot.EN.112.13           nest egg  zero_shot   \n",
            "2      train_zero_shot.EN.184.5         crime rate  zero_shot   \n",
            "3      train_zero_shot.EN.209.8      silver screen  zero_shot   \n",
            "4     train_zero_shot.EN.134.22  incubation period  zero_shot   \n",
            "...                         ...                ...        ...   \n",
            "1159    train_zero_shot.EN.75.7   world conference  zero_shot   \n",
            "1160   train_zero_shot.EN.194.5     lotus position  zero_shot   \n",
            "1161  train_zero_shot.EN.121.23       white spirit  zero_shot   \n",
            "1162  train_zero_shot.EN.224.10        memory lane  zero_shot   \n",
            "1163    train_zero_shot.EN.37.6        speed limit  zero_shot   \n",
            "\n",
            "                                               Previous  \\\n",
            "0     It's an ethical issue and everyone has their o...   \n",
            "1     A.G. Edwards' annual Nest Egg Index measures a...   \n",
            "2     The FBI tracks crime nationally in seven key c...   \n",
            "3     So while there are few films from them, there ...   \n",
            "4     What are the incubation periods of other respi...   \n",
            "...                                                 ...   \n",
            "1159     5th World Conference on Ecological Restoration   \n",
            "1160  I was a college freshman when I attended my fi...   \n",
            "1161  Firefighters have condemned a YouTube video sh...   \n",
            "1162  And as if this wasn’t enough, don’t forget to ...   \n",
            "1163  I work closely with the east precinct, they've...   \n",
            "\n",
            "                                                 Target  \\\n",
            "0     At the time of talking about fair play or equa...   \n",
            "1     It shows geographic regions where people are s...   \n",
            "2     Using those categories, Newport News’ violent ...   \n",
            "3     Generation Z actors grace the silver screen, t...   \n",
            "4     According to scientific evidence, the estimate...   \n",
            "...                                                 ...   \n",
            "1159  The SER2013 World Conference on Ecological Res...   \n",
            "1160  I sat in the lotus position for an hour and at...   \n",
            "1161  The video shows two boys near a river filling ...   \n",
            "1162  We hope you enjoy reading Memory Lane as much ...   \n",
            "1163  As for the cost, its estimated that replacing ...   \n",
            "\n",
            "                                                   Next  Label Language  \n",
            "0     In the end we all try to get the most out of o...      0       EN  \n",
            "1     Edwards residents are above the national avera...      0       EN  \n",
            "2     The other violent crimes held even or were dow...      1       EN  \n",
            "3     Marketing studies are taking an intense look a...      0       EN  \n",
            "4     In the case of MERS CoV, the average incubatio...      1       EN  \n",
            "...                                                 ...    ...      ...  \n",
            "1159  SER2013 is the 5th World Conference of the Soc...      1       EN  \n",
            "1160  My mind swarmed with thoughts, as I pushed awa...      0       EN  \n",
            "1161  They are then shown refilling the guns with wh...      0       EN  \n",
            "1162                          Want to buy a supplement?      1       EN  \n",
            "1163  Broken down, parts and materials will cost abo...      1       EN  \n",
            "\n",
            "[1164 rows x 8 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq33gURvTIFY",
        "outputId": "8f09bc9a-8d53-4b70-9416-a8ff4028c3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train_undersampled_multi_final.csv\n"
          ]
        }
      ],
      "source": [
        "train_multi=pd.read_csv(\"/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/train_zero_shot.csv\")\n",
        "#train_multi_df=pd.DataFrame(train_multi)\n",
        "X=train_multi.drop('Language',axis=1)\n",
        "y=train_multi['Language']\n",
        "under=RandomUnderSampler(sampling_strategy='majority')\n",
        "X_over, y_over = under.fit_resample(X, y)\n",
        "train_multi_undersampled = pd.concat([X_over, y_over], axis=1, join='inner')\n",
        "filepath=''\n",
        "train_en_undersampled.to_csv('Data/ZeroShot/train_en_undersampled.csv')\n",
        "train_data_multi = _get_train_data(\n",
        "        data_location   = 'Data/ZeroShot/',\n",
        "        file_name       = 'train_en_undersampled.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False,\n",
        "        language        = 'Multi'\n",
        "    )\n",
        "write_csv( train_data_multi, os.path.join( 'Data', 'ZeroShot', 'train_undersampled_multi_final.csv' ) )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=pd.read_csv('/content/Data/ZeroShot/train_undersampled_multi_final.csv')\n",
        "print(f)"
      ],
      "metadata": {
        "id": "fBGQK00lIn4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8837b2-795c-4023-9a82-3f135e0c9b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  It's an ethical issue and everyone has their o...\n",
            "1         0  A.G. Edwards' annual Nest Egg Index measures a...\n",
            "2         1  The FBI tracks crime nationally in seven key c...\n",
            "3         0  So while there are few films from them, there ...\n",
            "4         1  What are the incubation periods of other respi...\n",
            "...     ...                                                ...\n",
            "1159      1  5th World Conference on Ecological Restoration...\n",
            "1160      0  I was a college freshman when I attended my fi...\n",
            "1161      0  Firefighters have condemned a YouTube video sh...\n",
            "1162      1  And as if this wasn’t enough, don’t forget to ...\n",
            "1163      1  I work closely with the east precinct, they've...\n",
            "\n",
            "[1164 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xo2_HSYud0V"
      },
      "source": [
        "# *MFC class*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bpiJiP-udYo",
        "outputId": "597466b8-68bd-49db-d60f-342ef6e87912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the MFC for the trained on multilingual data and tested on multilingual data\n",
            "0.4546684709066306\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_multi.csv\"\n",
        "path_test_multi= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test_multi)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the trained on multilingual data and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh6IWq4Y_5l0",
        "outputId": "40d03008-ed50-46cb-ddb6-771c4c8a5ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "3322      0  He has recorded 95 tackles and just 6 sacks si...\n",
            "3323      0  But when the regulars started to return, Ighal...\n",
            "3324      0  My job as a head coach is to make the team as ...\n",
            "3325      0  Golden paper wasps have demanding social lives...\n",
            "3326      0  If only one is selected, mock drafters seem to...\n",
            "\n",
            "[3327 rows x 2 columns]\n",
            "This is the MFC for the trained on multilingual data and multilingual data\n",
            "0.4546684709066306\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_en.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the trained on multilingual data and multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77M-4LDn__6g",
        "outputId": "03a40deb-ea01-4e02-e819-b559c0b31eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "1         1  Explosões deixam 15 mortos e 500 feridos na Gu...\n",
            "2         1  O protagonista Alexander Pechersky vai liderar...\n",
            "3         1  Às vesperas das eleiçoes, milhares de mulheres...\n",
            "4         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "...     ...                                                ...\n",
            "1159      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "1160      0  De acordo com informações vazadas de dentro da...\n",
            "1161      0  O radialista Roberto Toledo apresentou o show ...\n",
            "1162      1  O carnaval em Goiânia também tem espaço para o...\n",
            "1163      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[1164 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on multilingual data\n",
            "0.4546684709066306\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_pt.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EhjK7hLPugQ",
        "outputId": "3375f63d-10af-4fb3-87b9-6738cd9331d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "4486      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "4487      0  De acordo com informações vazadas de dentro da...\n",
            "4488      0  O radialista Roberto Toledo apresentou o show ...\n",
            "4489      1  O carnaval em Goiânia também tem espaço para o...\n",
            "4490      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[4491 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on multilingual data\n",
            "0.3905579399141631\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_multi.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='EN']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRhhCR-1PunJ",
        "outputId": "56196b76-8bbf-4de9-8c82-fd6fc59bbc6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "3322      0  He has recorded 95 tackles and just 6 sacks si...\n",
            "3323      0  But when the regulars started to return, Ighal...\n",
            "3324      0  My job as a head coach is to make the team as ...\n",
            "3325      0  Golden paper wasps have demanding social lives...\n",
            "3326      0  If only one is selected, mock drafters seem to...\n",
            "\n",
            "[3327 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on multilingual data\n",
            "0.3905579399141631\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_en.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='EN']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on multilingual data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZUv2udfPutu",
        "outputId": "71c06317-38a8-4f8d-d821-c4703caf0227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "1         1  Explosões deixam 15 mortos e 500 feridos na Gu...\n",
            "2         1  O protagonista Alexander Pechersky vai liderar...\n",
            "3         1  Às vesperas das eleiçoes, milhares de mulheres...\n",
            "4         1  O presidente Teodoro Obiang Nguema, chefe de E...\n",
            "...     ...                                                ...\n",
            "1159      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "1160      0  De acordo com informações vazadas de dentro da...\n",
            "1161      0  O radialista Roberto Toledo apresentou o show ...\n",
            "1162      1  O carnaval em Goiânia também tem espaço para o...\n",
            "1163      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[1164 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on english data\n",
            "0.3905579399141631\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_pt.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='EN']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on english data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-XOYHDNQawo",
        "outputId": "987e728d-76be-4d9f-a3e8-d84bed2b6f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "4486      0  Era o ano de 1968.  A estação de passageiros t...\n",
            "4487      0  De acordo com informações vazadas de dentro da...\n",
            "4488      0  O radialista Roberto Toledo apresentou o show ...\n",
            "4489      1  O carnaval em Goiânia também tem espaço para o...\n",
            "4490      1  A concentração aconteceu na Avenida Circular, ...\n",
            "\n",
            "[4491 rows x 2 columns]\n",
            "This is the MFC for the portguese setup and tested on portuguese data\n",
            "0.5641025641025641\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_multi.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='PT']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the portguese setup and tested on portuguese data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN98bxxiQg-J",
        "outputId": "d0186bd2-0f26-4f92-8ad2-5d146145a253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                          sentence1\n",
            "0         0  This inspired others to jump ropes as a leisur...\n",
            "1         0  In the age of chivalry a man paid for the woma...\n",
            "2         0  To her eternal credit, she kept both India and...\n",
            "3         0  While pharmaceutical companies were researchin...\n",
            "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
            "...     ...                                                ...\n",
            "3322      0  He has recorded 95 tackles and just 6 sacks si...\n",
            "3323      0  But when the regulars started to return, Ighal...\n",
            "3324      0  My job as a head coach is to make the team as ...\n",
            "3325      0  Golden paper wasps have demanding social lives...\n",
            "3326      0  If only one is selected, mock drafters seem to...\n",
            "\n",
            "[3327 rows x 2 columns]\n",
            "This is the MFC for the english setup and tested on portuguese data\n",
            "0.5641025641025641\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "path_input=\"Data/ZeroShot/train_en.csv\"\n",
        "path_test= '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "df_train=pd.read_csv(path_input)\n",
        "df_test=pd.read_csv(path_test)\n",
        "df_test=df_test[df_test['Language']=='PT']\n",
        "print(df_train)\n",
        "dummy_clf=DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(df_train['sentence1'],df_train['label'])\n",
        "print(\"This is the MFC for the english setup and tested on portuguese data\")\n",
        "print(dummy_clf.score(df_test['Language'],df_test['Label']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP-Ol7hfoC8a"
      },
      "source": [
        "# Zero Shot Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-GiQvnkoL67"
      },
      "source": [
        "## Train Zero shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsA8WGYBFICe",
        "outputId": "00ff854b-26c3-4010-fa5a-81ba1eeb695c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/09/2022 19:34:13 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/09/2022 19:34:13 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.EPOCH,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/11/runs/Jun09_19-34-13_9a39e0b7c682,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=accuracy,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=models/ZeroShot/11/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/11/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "06/09/2022 19:34:13 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_multi.csv\n",
            "06/09/2022 19:34:13 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
            "06/09/2022 19:34:14 - WARNING - datasets.builder -   Using custom data configuration default-be708942b70b5e4f\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-be708942b70b5e4f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 11140.25it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 1305.01it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-be708942b70b5e4f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 1101.30it/s]\n",
            "[INFO|hub.py:583] 2022-06-09 19:34:15,250 >> https://huggingface.co/xlnet-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmprdiim7zh\n",
            "Downloading: 100% 760/760 [00:00<00:00, 791kB/s]\n",
            "[INFO|hub.py:587] 2022-06-09 19:34:16,133 >> storing https://huggingface.co/xlnet-base-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "[INFO|hub.py:595] 2022-06-09 19:34:16,133 >> creating metadata file for /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "[INFO|configuration_utils.py:659] 2022-06-09 19:34:16,133 >> loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "[INFO|configuration_utils.py:708] 2022-06-09 19:34:16,134 >> Model config XLNetConfig {\n",
            "  \"_name_or_path\": \"xlnet-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"XLNetLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"untie_r\": true,\n",
            "  \"use_mems_eval\": true,\n",
            "  \"use_mems_train\": false,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:371] 2022-06-09 19:34:17,026 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:659] 2022-06-09 19:34:17,896 >> loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "[INFO|configuration_utils.py:708] 2022-06-09 19:34:17,897 >> Model config XLNetConfig {\n",
            "  \"_name_or_path\": \"xlnet-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"XLNetLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"untie_r\": true,\n",
            "  \"use_mems_eval\": true,\n",
            "  \"use_mems_train\": false,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-06-09 19:34:19,660 >> https://huggingface.co/xlnet-base-cased/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpv79qc_7q\n",
            "Downloading: 100% 779k/779k [00:01<00:00, 750kB/s]\n",
            "[INFO|hub.py:587] 2022-06-09 19:34:21,616 >> storing https://huggingface.co/xlnet-base-cased/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/df73bc9f8d13bf2ea4dab95624895e45a550a0f0a825e41fc25440bf367ee3c8.d93497120e3a865e2970f26abdf7bf375896f97fde8b874b70909592a6c785c9\n",
            "[INFO|hub.py:595] 2022-06-09 19:34:21,616 >> creating metadata file for /root/.cache/huggingface/transformers/df73bc9f8d13bf2ea4dab95624895e45a550a0f0a825e41fc25440bf367ee3c8.d93497120e3a865e2970f26abdf7bf375896f97fde8b874b70909592a6c785c9\n",
            "[INFO|hub.py:583] 2022-06-09 19:34:22,499 >> https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpf8c9ef7c\n",
            "Downloading: 100% 1.32M/1.32M [00:01<00:00, 1.07MB/s]\n",
            "[INFO|hub.py:587] 2022-06-09 19:34:24,696 >> storing https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/46f47734f3dcaef7e236b9a3e887f27814e18836a8db7e6a49148000058a1a54.2a683f915238b4f560dab0c724066cf0a7de9a851e96b0fb3a1e7f0881552f53\n",
            "[INFO|hub.py:595] 2022-06-09 19:34:24,697 >> creating metadata file for /root/.cache/huggingface/transformers/46f47734f3dcaef7e236b9a3e887f27814e18836a8db7e6a49148000058a1a54.2a683f915238b4f560dab0c724066cf0a7de9a851e96b0fb3a1e7f0881552f53\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-06-09 19:34:27,328 >> loading file https://huggingface.co/xlnet-base-cased/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/df73bc9f8d13bf2ea4dab95624895e45a550a0f0a825e41fc25440bf367ee3c8.d93497120e3a865e2970f26abdf7bf375896f97fde8b874b70909592a6c785c9\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-06-09 19:34:27,329 >> loading file https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46f47734f3dcaef7e236b9a3e887f27814e18836a8db7e6a49148000058a1a54.2a683f915238b4f560dab0c724066cf0a7de9a851e96b0fb3a1e7f0881552f53\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-06-09 19:34:27,329 >> loading file https://huggingface.co/xlnet-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-06-09 19:34:27,329 >> loading file https://huggingface.co/xlnet-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-06-09 19:34:27,329 >> loading file https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:659] 2022-06-09 19:34:28,205 >> loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "[INFO|configuration_utils.py:708] 2022-06-09 19:34:28,206 >> Model config XLNetConfig {\n",
            "  \"_name_or_path\": \"xlnet-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"XLNetLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"untie_r\": true,\n",
            "  \"use_mems_eval\": true,\n",
            "  \"use_mems_train\": false,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-06-09 19:34:29,144 >> https://huggingface.co/xlnet-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmputxd6wu4\n",
            "Downloading: 100% 445M/445M [00:06<00:00, 77.2MB/s]\n",
            "[INFO|hub.py:587] 2022-06-09 19:34:35,278 >> storing https://huggingface.co/xlnet-base-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/9461853998373b0b2f8ef8011a13b62a2c5f540b2c535ef3ea46ed8a062b16a9.3e214f11a50e9e03eb47535b58522fc3cc11ac67c120a9450f6276de151af987\n",
            "[INFO|hub.py:595] 2022-06-09 19:34:35,278 >> creating metadata file for /root/.cache/huggingface/transformers/9461853998373b0b2f8ef8011a13b62a2c5f540b2c535ef3ea46ed8a062b16a9.3e214f11a50e9e03eb47535b58522fc3cc11ac67c120a9450f6276de151af987\n",
            "[INFO|modeling_utils.py:1953] 2022-06-09 19:34:35,279 >> loading weights file https://huggingface.co/xlnet-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9461853998373b0b2f8ef8011a13b62a2c5f540b2c535ef3ea46ed8a062b16a9.3e214f11a50e9e03eb47535b58522fc3cc11ac67c120a9450f6276de151af987\n",
            "[WARNING|modeling_utils.py:2255] 2022-06-09 19:34:36,442 >> Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2266] 2022-06-09 19:34:36,442 >> Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 5/5 [00:00<00:00,  5.49ba/s]\n",
            "100% 1/1 [00:00<00:00,  7.28ba/s]\n",
            "06/09/2022 19:34:37 - INFO - __main__ -   Sample 3155 of the training set: {'label': 0, 'sentence1': 'According to history.com, the leap day was originally discovered by Egyptian astronomers, but this discovery did not reach the western world until Julius Caesar’s reign in 45 BC. Caesar then created the leap year calendar to fix the problem, which was later adapted in accordance with new knowledge about the earth’s orbit by Pope Gregory into the Gregorian calendar that we observe today. Feb. 29 happens every four years, because the earth technically requires 365.25 days to complete its orbit around the sun.', 'input_ids': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1099, 22, 614, 9, 756, 19, 18, 9560, 191, 30, 2339, 2444, 37, 4296, 19645, 23, 19, 57, 52, 6072, 190, 50, 1287, 18, 2237, 185, 259, 19241, 18083, 165, 23, 7542, 25, 2566, 3913, 9, 18083, 137, 927, 18, 9560, 119, 5892, 22, 5229, 18, 662, 19, 59, 30, 266, 8615, 25, 7431, 33, 109, 1556, 75, 18, 2965, 165, 23, 8445, 37, 6286, 11750, 91, 18, 5721, 218, 884, 5892, 29, 80, 9051, 494, 9, 4096, 9, 1875, 3398, 300, 237, 123, 19, 149, 18, 2965, 13868, 2543, 17, 14770, 9, 1619, 307, 22, 1009, 81, 8445, 199, 18, 2176, 9, 4, 3], 'token_type_ids': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.\n",
            "06/09/2022 19:34:37 - INFO - __main__ -   Sample 3445 of the training set: {'label': 1, 'sentence1': 'A saída da crise, segundo Bachelet, depende de ações que garantam renda para os mais pobres e vacina para todos São Paulo – Alta comissária para os Direitos Humanos da Organização das Nações Unidas (ONU), a ex-presidenta do Chile Michelle Bachelet criticou governantes de países pobres e ricos que optaram pela economia em vez de promover a saúde da população. O resultado, segundo ela, foi o aprofundamento das desigualdades sociais causadas pela histórica falta de investimento em áreas sociais, entre elas a saúde.', 'input_ids': [79, 42, 101, 8075, 2349, 10204, 19, 17, 23, 4123, 15865, 12129, 6159, 46, 19, 6355, 93, 321, 24, 721, 202, 17, 1895, 17, 2753, 10716, 98, 17, 3236, 1011, 5815, 17, 1575, 17, 18714, 23, 7229, 6535, 23, 17, 93, 17, 11176, 1933, 5815, 22, 14334, 10739, 12058, 17, 14, 21945, 830, 8961, 8945, 5815, 17, 1575, 1717, 88, 10107, 23, 2976, 1575, 8075, 1137, 3152, 16798, 1346, 155, 17, 14066, 2203, 721, 202, 11135, 14066, 17, 10, 6288, 1580, 11, 19, 24, 2002, 13, 12026, 101, 112, 7224, 12094, 12129, 6159, 46, 7464, 3498, 12343, 6829, 23, 321, 7063, 2337, 23, 7229, 6535, 23, 17, 93, 17, 17051, 23, 17, 1895, 8959, 3068, 98, 17, 6884, 101, 17, 30083, 780, 10519, 17, 189, 553, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.\n",
            "06/09/2022 19:34:37 - INFO - __main__ -   Sample 331 of the training set: {'label': 1, 'sentence1': 'Concept Smoke Screen, in partnership with G4S, have developed a new way of defending cash and guards against attacks when replenishing ATM\\'s. On May 11th at the IFSEC Security Industry Awards 2009, Concept Smoke Screen were honoured with the \"Physical Security Product of the Year\" award, for the Guardian Smoke Screen. The ceremony was conducted at the Birmingham Hilton Metropole.', 'input_ids': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 22833, 17, 83, 98, 10190, 12728, 19, 25, 4164, 33, 457, 265, 83, 19, 47, 1231, 24, 109, 162, 20, 5667, 1454, 21, 5485, 157, 1076, 90, 25101, 56, 21564, 26, 23, 9, 240, 428, 506, 138, 38, 18, 35, 11966, 3193, 1424, 6680, 4660, 1307, 19, 22833, 17, 83, 98, 10190, 12728, 55, 6932, 68, 33, 18, 17, 12, 14077, 117, 23, 4140, 1424, 9841, 20, 18, 2671, 12, 2275, 19, 28, 18, 11544, 17, 83, 98, 10190, 12728, 9, 32, 3057, 30, 2496, 38, 18, 8847, 14725, 7117, 15585, 9, 4, 3], 'token_type_ids': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.\n",
            "[INFO|trainer.py:623] 2022-06-09 19:34:51,854 >> The following columns in the training set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1419] 2022-06-09 19:34:51,860 >> ***** Running training *****\n",
            "[INFO|trainer.py:1420] 2022-06-09 19:34:51,860 >>   Num examples = 4491\n",
            "[INFO|trainer.py:1421] 2022-06-09 19:34:51,860 >>   Num Epochs = 9\n",
            "[INFO|trainer.py:1422] 2022-06-09 19:34:51,860 >>   Instantaneous batch size per device = 32\n",
            "[INFO|trainer.py:1423] 2022-06-09 19:34:51,860 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1424] 2022-06-09 19:34:51,860 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1425] 2022-06-09 19:34:51,860 >>   Total optimization steps = 1269\n",
            " 11% 141/1269 [01:57<13:01,  1.44it/s][INFO|trainer.py:623] 2022-06-09 19:36:49,254 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:36:49,256 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:36:49,256 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:36:49,256 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 19.47it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 15.58it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:05, 14.48it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.85it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 13.56it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:05, 13.35it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:05, 13.24it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:05, 13.17it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 13.07it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 13.09it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 13.01it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.99it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.98it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:04, 12.94it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 13.01it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.98it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 13.02it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 13.00it/s]\u001b[A\n",
            " 42% 39/93 [00:02<00:04, 12.98it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:03, 13.02it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 13.00it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 13.01it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 13.00it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 13.03it/s]\u001b[A\n",
            " 55% 51/93 [00:03<00:03, 13.00it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.97it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:02, 13.02it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.98it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 13.02it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.97it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.96it/s]\u001b[A\n",
            " 70% 65/93 [00:04<00:02, 12.96it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.92it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.99it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.98it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.98it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.96it/s]\u001b[A\n",
            " 83% 77/93 [00:05<00:01, 12.91it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.98it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.97it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.99it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.97it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.93it/s]\u001b[A\n",
            " 96% 89/93 [00:06<00:00, 12.97it/s]\u001b[A\n",
            " 98% 91/93 [00:06<00:00, 12.92it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.6883295178413391, 'eval_accuracy': 0.6454668641090393, 'eval_f1': 0.6392515911699383, 'eval_runtime': 7.1193, 'eval_samples_per_second': 103.803, 'eval_steps_per_second': 13.063, 'epoch': 1.0}\n",
            " 11% 141/1269 [02:04<13:01,  1.44it/s]\n",
            "100% 93/93 [00:07<00:00, 14.21it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:36:56,376 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-141\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:36:56,377 >> Configuration saved in models/ZeroShot/11/checkpoint-141/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:36:57,740 >> Model weights saved in models/ZeroShot/11/checkpoint-141/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:36:57,740 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-141/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:36:57,740 >> Special tokens file saved in models/ZeroShot/11/checkpoint-141/special_tokens_map.json\n",
            " 22% 282/1269 [04:09<11:35,  1.42it/s][INFO|trainer.py:623] 2022-06-09 19:39:01,469 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:39:01,471 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:39:01,471 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:39:01,471 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.62it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 15.09it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.97it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.48it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 13.18it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.90it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.80it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:05, 12.76it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.78it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.75it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.72it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.63it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.66it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.71it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.69it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.67it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.66it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.70it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.70it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.69it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 12.69it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.74it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.73it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.70it/s]\u001b[A\n",
            " 55% 51/93 [00:03<00:03, 12.71it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.76it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:02, 12.70it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.68it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.68it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.69it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.67it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.62it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.59it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.54it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.53it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.59it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.63it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.60it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.60it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.62it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.69it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.67it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.62it/s]\u001b[A\n",
            " 96% 89/93 [00:06<00:00, 12.58it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.62it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.7236476540565491, 'eval_accuracy': 0.6346414089202881, 'eval_f1': 0.6342227990672709, 'eval_runtime': 7.3039, 'eval_samples_per_second': 101.179, 'eval_steps_per_second': 12.733, 'epoch': 2.0}\n",
            " 22% 282/1269 [04:16<11:35,  1.42it/s]\n",
            "100% 93/93 [00:07<00:00, 13.91it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:39:08,776 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-282\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:39:08,777 >> Configuration saved in models/ZeroShot/11/checkpoint-282/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:39:09,590 >> Model weights saved in models/ZeroShot/11/checkpoint-282/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:39:09,591 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-282/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:39:09,591 >> Special tokens file saved in models/ZeroShot/11/checkpoint-282/special_tokens_map.json\n",
            " 33% 423/1269 [06:23<10:00,  1.41it/s][INFO|trainer.py:623] 2022-06-09 19:41:15,454 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:41:15,456 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:41:15,456 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:41:15,456 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.61it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 15.04it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.95it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.49it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 13.16it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.90it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.76it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:05, 12.67it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.66it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.69it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.67it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.61it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.58it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.55it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.56it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.62it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.64it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.60it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.59it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.58it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 12.62it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.66it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.64it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.62it/s]\u001b[A\n",
            " 55% 51/93 [00:03<00:03, 12.58it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.64it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:02, 12.67it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.66it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.62it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.60it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.61it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.67it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.64it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.62it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.59it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.61it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.66it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.63it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.60it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.58it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.54it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.50it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.57it/s]\u001b[A\n",
            " 96% 89/93 [00:06<00:00, 12.59it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.59it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.9302243590354919, 'eval_accuracy': 0.6495263576507568, 'eval_f1': 0.6435104906827092, 'eval_runtime': 7.3337, 'eval_samples_per_second': 100.767, 'eval_steps_per_second': 12.681, 'epoch': 3.0}\n",
            " 33% 423/1269 [06:30<10:00,  1.41it/s]\n",
            "100% 93/93 [00:07<00:00, 13.83it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:41:22,791 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-423\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:41:22,792 >> Configuration saved in models/ZeroShot/11/checkpoint-423/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:41:23,588 >> Model weights saved in models/ZeroShot/11/checkpoint-423/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:41:23,589 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-423/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:41:23,589 >> Special tokens file saved in models/ZeroShot/11/checkpoint-423/special_tokens_map.json\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:41:27,113 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-141] due to args.save_total_limit\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:41:27,259 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-282] due to args.save_total_limit\n",
            "{'loss': 0.3378, 'learning_rate': 1.2119779353821908e-05, 'epoch': 3.55}\n",
            " 44% 564/1269 [08:38<08:20,  1.41it/s][INFO|trainer.py:623] 2022-06-09 19:43:30,051 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:43:30,052 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:43:30,053 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:43:30,053 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.47it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 14.94it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.80it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.20it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 12.91it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.66it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.58it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:06, 12.52it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.51it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.58it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.63it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.61it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.56it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.50it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.46it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.40it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.40it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.39it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.35it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.36it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:04, 12.38it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.41it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.48it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.53it/s]\u001b[A\n",
            " 55% 51/93 [00:04<00:03, 12.56it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.58it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:03, 12.54it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.55it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.60it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.61it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.58it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.55it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.51it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.45it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.44it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.40it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.39it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.35it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.39it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.43it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.50it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.52it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.54it/s]\u001b[A\n",
            " 96% 89/93 [00:07<00:00, 12.52it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.49it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.2449702024459839, 'eval_accuracy': 0.6535859107971191, 'eval_f1': 0.6516564290659478, 'eval_runtime': 7.411, 'eval_samples_per_second': 99.717, 'eval_steps_per_second': 12.549, 'epoch': 4.0}\n",
            " 44% 564/1269 [08:45<08:20,  1.41it/s]\n",
            "100% 93/93 [00:07<00:00, 13.69it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:43:37,465 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-564\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:43:37,466 >> Configuration saved in models/ZeroShot/11/checkpoint-564/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:43:38,296 >> Model weights saved in models/ZeroShot/11/checkpoint-564/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:43:38,297 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-564/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:43:38,297 >> Special tokens file saved in models/ZeroShot/11/checkpoint-564/special_tokens_map.json\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:43:41,591 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-423] due to args.save_total_limit\n",
            " 56% 705/1269 [10:52<06:40,  1.41it/s][INFO|trainer.py:623] 2022-06-09 19:45:44,509 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:45:44,511 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:45:44,511 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:45:44,511 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.35it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 14.86it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.74it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.14it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 12.85it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.66it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.57it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:06, 12.55it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.55it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.59it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.62it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.59it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.54it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.53it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.47it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.44it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.45it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.50it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.58it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.59it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 12.56it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.50it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.51it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.47it/s]\u001b[A\n",
            " 55% 51/93 [00:04<00:03, 12.56it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.61it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:03, 12.58it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.57it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.51it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.44it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.43it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.42it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.41it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.40it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.41it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.49it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.52it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.53it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.51it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.50it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.47it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.42it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.40it/s]\u001b[A\n",
            " 96% 89/93 [00:07<00:00, 12.39it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.40it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.6158781051635742, 'eval_accuracy': 0.6562922596931458, 'eval_f1': 0.6551246435605727, 'eval_runtime': 7.4094, 'eval_samples_per_second': 99.738, 'eval_steps_per_second': 12.552, 'epoch': 5.0}\n",
            " 56% 705/1269 [11:00<06:40,  1.41it/s]\n",
            "100% 93/93 [00:07<00:00, 13.67it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:45:51,922 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-705\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:45:51,922 >> Configuration saved in models/ZeroShot/11/checkpoint-705/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:45:52,713 >> Model weights saved in models/ZeroShot/11/checkpoint-705/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:45:52,714 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-705/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:45:52,714 >> Special tokens file saved in models/ZeroShot/11/checkpoint-705/special_tokens_map.json\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:45:56,013 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-564] due to args.save_total_limit\n",
            " 67% 846/1269 [13:06<05:00,  1.41it/s][INFO|trainer.py:623] 2022-06-09 19:47:58,862 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:47:58,864 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:47:58,864 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:47:58,864 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.58it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 14.97it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.83it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.33it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 13.09it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.92it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.81it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:05, 12.69it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.60it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.56it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.59it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.63it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.60it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.57it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.54it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.47it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.50it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.54it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.61it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.56it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 12.53it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.51it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.48it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.44it/s]\u001b[A\n",
            " 55% 51/93 [00:03<00:03, 12.44it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.42it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:03, 12.45it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.52it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.55it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.53it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.51it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.49it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.42it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.41it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.41it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.42it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.42it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.43it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.41it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.48it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.53it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.55it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.50it/s]\u001b[A\n",
            " 96% 89/93 [00:07<00:00, 12.49it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.46it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.8172533512115479, 'eval_accuracy': 0.6603518128395081, 'eval_f1': 0.6603120187086697, 'eval_runtime': 7.3954, 'eval_samples_per_second': 99.927, 'eval_steps_per_second': 12.575, 'epoch': 6.0}\n",
            " 67% 846/1269 [13:14<05:00,  1.41it/s]\n",
            "100% 93/93 [00:07<00:00, 13.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:48:06,260 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-846\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:48:06,261 >> Configuration saved in models/ZeroShot/11/checkpoint-846/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:48:07,013 >> Model weights saved in models/ZeroShot/11/checkpoint-846/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:48:07,014 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-846/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:48:07,014 >> Special tokens file saved in models/ZeroShot/11/checkpoint-846/special_tokens_map.json\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:48:10,328 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-705] due to args.save_total_limit\n",
            " 78% 987/1269 [15:21<03:20,  1.41it/s][INFO|trainer.py:623] 2022-06-09 19:50:13,233 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:50:13,235 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:50:13,235 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:50:13,235 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.35it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 14.97it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.92it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.38it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 13.08it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.89it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.75it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:06, 12.66it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.61it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.64it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.62it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.58it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.53it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.53it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.46it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.45it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.44it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.40it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.41it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.46it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 12.51it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.54it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.53it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.50it/s]\u001b[A\n",
            " 55% 51/93 [00:04<00:03, 12.48it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.48it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:03, 12.49it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.54it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.58it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.56it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.51it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.51it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.50it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.46it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.43it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.38it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.40it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.36it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.38it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.38it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.36it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.36it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.36it/s]\u001b[A\n",
            " 96% 89/93 [00:07<00:00, 12.34it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.33it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.3198513984680176, 'eval_accuracy': 0.6684709191322327, 'eval_f1': 0.6669462732307987, 'eval_runtime': 7.4156, 'eval_samples_per_second': 99.655, 'eval_steps_per_second': 12.541, 'epoch': 7.0}\n",
            " 78% 987/1269 [15:28<03:20,  1.41it/s]\n",
            "100% 93/93 [00:07<00:00, 13.54it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:50:20,652 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-987\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:50:20,653 >> Configuration saved in models/ZeroShot/11/checkpoint-987/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:50:21,453 >> Model weights saved in models/ZeroShot/11/checkpoint-987/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:50:21,453 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-987/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:50:21,453 >> Special tokens file saved in models/ZeroShot/11/checkpoint-987/special_tokens_map.json\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:50:24,883 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-846] due to args.save_total_limit\n",
            "{'loss': 0.0661, 'learning_rate': 4.239558707643815e-06, 'epoch': 7.09}\n",
            " 89% 1128/1269 [17:35<01:40,  1.41it/s][INFO|trainer.py:623] 2022-06-09 19:52:27,835 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:52:27,837 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:52:27,837 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:52:27,838 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.38it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 14.91it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.73it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.15it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 12.86it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.67it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.57it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:06, 12.49it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.44it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.45it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.45it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.50it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.56it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.57it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.54it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.51it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.47it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.44it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.39it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.37it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:04, 12.40it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.40it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.44it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.52it/s]\u001b[A\n",
            " 55% 51/93 [00:04<00:03, 12.55it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.54it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:03, 12.49it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.48it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.44it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.37it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.35it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.34it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.33it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.33it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.33it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.35it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.35it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.30it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.30it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.29it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.32it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.35it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.36it/s]\u001b[A\n",
            " 96% 89/93 [00:07<00:00, 12.34it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.29it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.5051722526550293, 'eval_accuracy': 0.6617050170898438, 'eval_f1': 0.6579919732243351, 'eval_runtime': 7.4558, 'eval_samples_per_second': 99.117, 'eval_steps_per_second': 12.473, 'epoch': 8.0}\n",
            " 89% 1128/1269 [17:43<01:40,  1.41it/s]\n",
            "100% 93/93 [00:07<00:00, 13.50it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:52:35,295 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-1128\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:52:35,296 >> Configuration saved in models/ZeroShot/11/checkpoint-1128/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:52:36,114 >> Model weights saved in models/ZeroShot/11/checkpoint-1128/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:52:36,115 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-1128/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:52:36,115 >> Special tokens file saved in models/ZeroShot/11/checkpoint-1128/special_tokens_map.json\n",
            "100% 1269/1269 [19:50<00:00,  1.40it/s][INFO|trainer.py:623] 2022-06-09 19:54:42,427 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:54:42,429 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:54:42,429 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:54:42,429 >>   Batch size = 8\n",
            "\n",
            "  0% 0/93 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 3/93 [00:00<00:04, 18.56it/s]\u001b[A\n",
            "  5% 5/93 [00:00<00:05, 14.91it/s]\u001b[A\n",
            "  8% 7/93 [00:00<00:06, 13.73it/s]\u001b[A\n",
            " 10% 9/93 [00:00<00:06, 13.16it/s]\u001b[A\n",
            " 12% 11/93 [00:00<00:06, 12.84it/s]\u001b[A\n",
            " 14% 13/93 [00:00<00:06, 12.64it/s]\u001b[A\n",
            " 16% 15/93 [00:01<00:06, 12.55it/s]\u001b[A\n",
            " 18% 17/93 [00:01<00:06, 12.48it/s]\u001b[A\n",
            " 20% 19/93 [00:01<00:05, 12.53it/s]\u001b[A\n",
            " 23% 21/93 [00:01<00:05, 12.58it/s]\u001b[A\n",
            " 25% 23/93 [00:01<00:05, 12.59it/s]\u001b[A\n",
            " 27% 25/93 [00:01<00:05, 12.56it/s]\u001b[A\n",
            " 29% 27/93 [00:02<00:05, 12.51it/s]\u001b[A\n",
            " 31% 29/93 [00:02<00:05, 12.50it/s]\u001b[A\n",
            " 33% 31/93 [00:02<00:04, 12.49it/s]\u001b[A\n",
            " 35% 33/93 [00:02<00:04, 12.49it/s]\u001b[A\n",
            " 38% 35/93 [00:02<00:04, 12.53it/s]\u001b[A\n",
            " 40% 37/93 [00:02<00:04, 12.57it/s]\u001b[A\n",
            " 42% 39/93 [00:03<00:04, 12.57it/s]\u001b[A\n",
            " 44% 41/93 [00:03<00:04, 12.57it/s]\u001b[A\n",
            " 46% 43/93 [00:03<00:03, 12.54it/s]\u001b[A\n",
            " 48% 45/93 [00:03<00:03, 12.53it/s]\u001b[A\n",
            " 51% 47/93 [00:03<00:03, 12.50it/s]\u001b[A\n",
            " 53% 49/93 [00:03<00:03, 12.56it/s]\u001b[A\n",
            " 55% 51/93 [00:04<00:03, 12.60it/s]\u001b[A\n",
            " 57% 53/93 [00:04<00:03, 12.59it/s]\u001b[A\n",
            " 59% 55/93 [00:04<00:03, 12.56it/s]\u001b[A\n",
            " 61% 57/93 [00:04<00:02, 12.52it/s]\u001b[A\n",
            " 63% 59/93 [00:04<00:02, 12.48it/s]\u001b[A\n",
            " 66% 61/93 [00:04<00:02, 12.49it/s]\u001b[A\n",
            " 68% 63/93 [00:04<00:02, 12.55it/s]\u001b[A\n",
            " 70% 65/93 [00:05<00:02, 12.59it/s]\u001b[A\n",
            " 72% 67/93 [00:05<00:02, 12.59it/s]\u001b[A\n",
            " 74% 69/93 [00:05<00:01, 12.54it/s]\u001b[A\n",
            " 76% 71/93 [00:05<00:01, 12.47it/s]\u001b[A\n",
            " 78% 73/93 [00:05<00:01, 12.46it/s]\u001b[A\n",
            " 81% 75/93 [00:05<00:01, 12.43it/s]\u001b[A\n",
            " 83% 77/93 [00:06<00:01, 12.40it/s]\u001b[A\n",
            " 85% 79/93 [00:06<00:01, 12.41it/s]\u001b[A\n",
            " 87% 81/93 [00:06<00:00, 12.39it/s]\u001b[A\n",
            " 89% 83/93 [00:06<00:00, 12.41it/s]\u001b[A\n",
            " 91% 85/93 [00:06<00:00, 12.47it/s]\u001b[A\n",
            " 94% 87/93 [00:06<00:00, 12.54it/s]\u001b[A\n",
            " 96% 89/93 [00:07<00:00, 12.54it/s]\u001b[A\n",
            " 98% 91/93 [00:07<00:00, 12.52it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.576544761657715, 'eval_accuracy': 0.6698240637779236, 'eval_f1': 0.6681170303619283, 'eval_runtime': 7.3988, 'eval_samples_per_second': 99.881, 'eval_steps_per_second': 12.57, 'epoch': 9.0}\n",
            "100% 1269/1269 [19:57<00:00,  1.40it/s]\n",
            "100% 93/93 [00:07<00:00, 13.72it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2340] 2022-06-09 19:54:49,829 >> Saving model checkpoint to models/ZeroShot/11/checkpoint-1269\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:54:49,830 >> Configuration saved in models/ZeroShot/11/checkpoint-1269/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:54:50,640 >> Model weights saved in models/ZeroShot/11/checkpoint-1269/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:54:50,641 >> tokenizer config file saved in models/ZeroShot/11/checkpoint-1269/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:54:50,641 >> Special tokens file saved in models/ZeroShot/11/checkpoint-1269/special_tokens_map.json\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:54:54,198 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-987] due to args.save_total_limit\n",
            "[INFO|trainer.py:2418] 2022-06-09 19:54:54,335 >> Deleting older checkpoint [models/ZeroShot/11/checkpoint-1128] due to args.save_total_limit\n",
            "[INFO|trainer.py:1662] 2022-06-09 19:54:54,474 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1727] 2022-06-09 19:54:54,475 >> Loading best model from models/ZeroShot/11/checkpoint-1269 (score: 0.6698240637779236).\n",
            "{'train_runtime': 1202.9565, 'train_samples_per_second': 33.6, 'train_steps_per_second': 1.055, 'train_loss': 0.16277238080781498, 'epoch': 9.0}\n",
            "100% 1269/1269 [20:02<00:00,  1.05it/s]\n",
            "[INFO|trainer.py:2340] 2022-06-09 19:54:54,818 >> Saving model checkpoint to models/ZeroShot/11/\n",
            "[INFO|configuration_utils.py:446] 2022-06-09 19:54:54,819 >> Configuration saved in models/ZeroShot/11/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-06-09 19:54:55,682 >> Model weights saved in models/ZeroShot/11/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-06-09 19:54:55,683 >> tokenizer config file saved in models/ZeroShot/11/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-06-09 19:54:55,683 >> Special tokens file saved in models/ZeroShot/11/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        9.0\n",
            "  train_loss               =     0.1628\n",
            "  train_runtime            = 0:20:02.95\n",
            "  train_samples            =       4491\n",
            "  train_samples_per_second =       33.6\n",
            "  train_steps_per_second   =      1.055\n",
            "06/09/2022 19:54:55 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:623] 2022-06-09 19:54:55,720 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:54:55,721 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:54:55,722 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:54:55,722 >>   Batch size = 8\n",
            "100% 93/93 [00:07<00:00, 12.78it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        9.0\n",
            "  eval_accuracy           =     0.6698\n",
            "  eval_f1                 =     0.6681\n",
            "  eval_loss               =     2.5765\n",
            "  eval_runtime            = 0:00:07.39\n",
            "  eval_samples            =        739\n",
            "  eval_samples_per_second =     99.934\n",
            "  eval_steps_per_second   =     12.576\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "    \t--do_train \\\n",
        "    \t--do_eval \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/11/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"accuracy\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54PqcPHuFLgk"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "#     \t--do_train \\\n",
        "#     \t--do_eval \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/2/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_pt.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"accuracy\" \\\n",
        "# \t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFFqAwoaFDWi"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "#     \t--do_train \\\n",
        "#     \t--do_eval \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/6/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_undersampled_final.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"accuracy\" \\\n",
        "# \t    --save_total_limit 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGlY2qvVTQ1X"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "#     \t--do_train \\\n",
        "#     \t--do_eval \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/5/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"accuracy\" \\\n",
        "# \t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrfwDiORPDyS",
        "outputId": "8618e0ad-f77c-4d4d-ff16-14be17729838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibb2Uo0vPPc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d0565b-736d-467d-e5e2-c9fd49faec7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/models/ZeroShot/0/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "## Create save path\n",
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/0/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bnemEFMFllZ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/11/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd5n2LxvFlxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea669cb8-098c-4c9f-8558-3056a7905b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/models/ZeroShot/2/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/2/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/2/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a01lXW3pE86c",
        "outputId": "5c383a1a-4bb4-4346-e2c8-86b4be1becce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/models/ZeroShot/6/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/6/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/6/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/6/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0s4_Y2YTaSs",
        "outputId": "68d6c993-f9c4-4c69-bf74-d328a1f296f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/models/ZeroShot/5/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/5/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/5/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/5/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_ag-2oV4Egv"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/SemEval_2022_Task2-idiomaticity\n",
        "## Copy saved model.\n",
        "!cp -r SemEval_2022_Task2-idiomaticity/* /content/gdrive/MyDrive/SemEval_2022_Task2-idiomaticity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etL-Ic6bPmtA"
      },
      "outputs": [],
      "source": [
        "## Bring back saved model here.\n",
        "#!mkdir -p /content/models/ZeroShot/0/\n",
        "# !cp -r /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/* /content/models/ZeroShot/0/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bN4iUHWP45b"
      },
      "source": [
        "## Evaluation On Dev Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "houOZpcYO-Pw"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/' \\\n",
        "#     \t--do_predict \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/0/eval-dev/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_multi.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "#       --test_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"f1\" \\\n",
        "# \t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W0KeQZPFADP",
        "outputId": "20eb92e4-4b53-42bb-cb6c-38d62964670f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/09/2022 19:58:13 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/09/2022 19:58:13 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.EPOCH,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/11/eval-dev/runs/Jun09_19-58-13_9a39e0b7c682,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=f1,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=models/ZeroShot/11/eval-dev/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/11/eval-dev/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "06/09/2022 19:58:13 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_multi.csv\n",
            "06/09/2022 19:58:13 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
            "06/09/2022 19:58:13 - INFO - __main__ -   load a local file for test: Data/ZeroShot/dev.csv\n",
            "06/09/2022 19:58:14 - WARNING - datasets.builder -   Using custom data configuration default-5238193fac94a585\n",
            "06/09/2022 19:58:14 - WARNING - datasets.builder -   Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-5238193fac94a585/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "100% 3/3 [00:00<00:00, 1130.44it/s]\n",
            "[INFO|configuration_utils.py:657] 2022-06-09 19:58:14,402 >> loading configuration file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/config.json\n",
            "[INFO|configuration_utils.py:708] 2022-06-09 19:58:14,403 >> Model config XLNetConfig {\n",
            "  \"_name_or_path\": \"/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/\",\n",
            "  \"architectures\": [\n",
            "    \"XLNetForSequenceClassification\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"untie_r\": true,\n",
            "  \"use_mems_eval\": true,\n",
            "  \"use_mems_train\": false,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1702] 2022-06-09 19:58:14,407 >> Didn't find file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1780] 2022-06-09 19:58:14,408 >> loading file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/spiece.model\n",
            "[INFO|tokenization_utils_base.py:1780] 2022-06-09 19:58:14,408 >> loading file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1780] 2022-06-09 19:58:14,408 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1780] 2022-06-09 19:58:14,408 >> loading file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1780] 2022-06-09 19:58:14,408 >> loading file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1951] 2022-06-09 19:58:14,479 >> loading weights file /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2263] 2022-06-09 19:58:15,684 >> All model checkpoint weights were used when initializing XLNetForSequenceClassification.\n",
            "\n",
            "[INFO|modeling_utils.py:2272] 2022-06-09 19:58:15,684 >> All the weights of XLNetForSequenceClassification were initialized from the model checkpoint at /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLNetForSequenceClassification for predictions without further training.\n",
            "06/09/2022 19:58:15 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5238193fac94a585/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8c73a3dfca516626.arrow\n",
            "06/09/2022 19:58:15 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5238193fac94a585/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e8fb777e7faaac35.arrow\n",
            "06/09/2022 19:58:15 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5238193fac94a585/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-e32385b3486915a1.arrow\n",
            "06/09/2022 19:58:20 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:623] 2022-06-09 19:58:20,163 >> The following columns in the evaluation set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:58:20,164 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:58:20,164 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:58:20,164 >>   Batch size = 8\n",
            "100% 93/93 [00:06<00:00, 13.71it/s]\n",
            "***** eval metrics *****\n",
            "  eval_accuracy           =     0.6698\n",
            "  eval_f1                 =     0.6681\n",
            "  eval_loss               =     2.5765\n",
            "  eval_runtime            = 0:00:06.90\n",
            "  eval_samples            =        739\n",
            "  eval_samples_per_second =    107.048\n",
            "  eval_steps_per_second   =     13.472\n",
            "06/09/2022 19:58:27 - INFO - __main__ -   *** Test ***\n",
            "[INFO|trainer.py:623] 2022-06-09 19:58:27,070 >> The following columns in the test set don't have a corresponding argument in `XLNetForSequenceClassification.forward` and have been ignored: sentence1. If sentence1 are not expected by `XLNetForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2590] 2022-06-09 19:58:27,072 >> ***** Running Prediction *****\n",
            "[INFO|trainer.py:2592] 2022-06-09 19:58:27,072 >>   Num examples = 739\n",
            "[INFO|trainer.py:2595] 2022-06-09 19:58:27,072 >>   Batch size = 8\n",
            " 99% 92/93 [00:06<00:00, 13.47it/s]06/09/2022 19:58:33 - INFO - __main__ -   ***** Test results None *****\n",
            "100% 93/93 [00:06<00:00, 13.72it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/11/' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/11/eval-dev/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDb4e_UyFzaO"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/2/' \\\n",
        "#     \t--do_predict \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/2/eval-dev/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_pt.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "#       --test_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"f1\" \\\n",
        "# \t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhV-IAvwFMo7"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/6/' \\\n",
        "#     \t--do_predict \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/6/eval-dev/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_undersampled_final.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "#       --test_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"f1\" \\\n",
        "# \t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3P5QsGNTf27"
      },
      "outputs": [],
      "source": [
        "# !python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "#     \t--model_name_or_path '/content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/5/' \\\n",
        "#     \t--do_predict \\\n",
        "#     \t--max_seq_length 128 \\\n",
        "#     \t--per_device_train_batch_size 32 \\\n",
        "#     \t--learning_rate 2e-5 \\\n",
        "#     \t--num_train_epochs 9 \\\n",
        "#     \t--evaluation_strategy \"epoch\" \\\n",
        "#     \t--output_dir models/ZeroShot/5/eval-dev/ \\\n",
        "#     \t--seed 0 \\\n",
        "#     \t--train_file      Data/ZeroShot/train_undersampled_multi_final.csv \\\n",
        "#     \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "#       --test_file Data/ZeroShot/dev.csv \\\n",
        "# \t    --evaluation_strategy \"epoch\" \\\n",
        "# \t    --save_strategy \"epoch\"  \\\n",
        "# \t    --load_best_model_at_end \\\n",
        "# \t    --metric_for_best_model \"f1\" \\\n",
        "# \t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHqPYuTS3muJ"
      },
      "source": [
        "### Use predictions to create the submission file (for dev data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfWUuwg7Qm-t"
      },
      "outputs": [],
      "source": [
        "params_multi = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/11/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_multi[ 'setting' ] = 'zero_shot'\n",
        "params_en = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/11/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_en[ 'setting' ] = 'zero_shot'\n",
        "params_pt = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/2/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_pt[ 'setting' ] = 'zero_shot'\n",
        "params_undersampled = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/6/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_undersampled[ 'setting' ] = 'zero_shot'\n",
        "params_undersampled_multi = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/5/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params_undersampled_multi[ 'setting' ] = 'zero_shot'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgFGlGnTROJZ"
      },
      "outputs": [],
      "source": [
        "updated_data_multi = insert_to_submission_file( **params_multi )\n",
        "#updated_data_en = insert_to_submission_file( **params_en )\n",
        "#updated_data_pt = insert_to_submission_file( **params_pt )\n",
        "# updated_data_undersampled = insert_to_submission_file( **params_undersampled )\n",
        "# updated_data_undersampled_multi = insert_to_submission_file( **params_undersampled_multi )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8-WO4T8LBgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e22d5b-13a8-485f-e875-05474618e735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXcRbv70RZfR"
      },
      "outputs": [],
      "source": [
        "!mkdir -p outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ezIzyWTRePp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8881d2-befa-4b9e-8088-1cba8dba83ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote outputs/zero_shot_dev_formated_multi.csv\n"
          ]
        }
      ],
      "source": [
        "write_csv( updated_data_multi, 'outputs/zero_shot_dev_formated_multi.csv' )\n",
        "#write_csv( updated_data_en, 'outputs/zero_shot_dev_formated_en.csv' )\n",
        "#write_csv( updated_data_pt, 'outputs/zero_shot_dev_formated_pt.csv' )\n",
        "# write_csv( updated_data_undersampled, 'outputs/zero_shot_dev_formated_undersampled.csv' )\n",
        "# write_csv( updated_data_undersampled_multi, 'outputs/zero_shot_dev_formated_undersampled_multi.csv' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q2Hxtg6AM1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "88a3bf0b-0cd9-46c1-bedf-2a803bc6c2e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-179083a9f990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/outputs/zero_shot_dev_formated_en.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/outputs/zero_shot_dev_formated_en.csv"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/outputs/zero_shot_dev_formated_en.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}